\lstset{style=plain}

\chapter{Evaluation} \label{evaluation}

The main goal of this chapter is to give some insights about the factors that affect performance and compare different variants of the synthesis procedure described in Chapter~\ref{ch:definitions}. The chapter also puts our synthesis procedure in relation with the related work discussed in Chapter~\ref{ch:relatedwork}.


\section{Experimental set up}
This section presents the set up of the two experiments we are going to discuss in the rest of the chapter.

The goal of the first experiment is to assess the quality and the performance of the synthesiser on standard benchmarks. The detailed set up is described in Section~\ref{Evaluation on benchmarks} and the results are discussed in Section~\ref{Table summary}. Section~\ref{Factors affecting runtime} discusses the factors that affect the runtime.

In the second experiment the synthesiser is used to automatically generate a \emph{black list} that can successively be used to prune the search space. We refer back to Section~\ref{Black list} for a description of pruning based on black lists. Section~\ref{Black list generation} describes how we used the synthesis procedure to generate a black list and Section~\ref{Automatic black list} reviews the quality of the generated black list.

All experiments were run on an Intel quad core 3.2~GHz with 16~GB RAM. Since the code is sequential, the performance could not benefit from the number of cores. The performance numbers are averages from 1 to 3 different executions all sharing the same specification, that is the goal type, the given examples and the set of components do not change between different executions.

\section{Performance evaluation}\label{Evaluation on benchmarks}

We evaluated nine variants of our synthesis procedure, crossing the three exploration strategies with three of the cost functions described in Chapter~\ref{ch:definitions}. The three exploration strategies we evaluated are the following.

\begin{description}
\item[\mdseries\textsc{Plain}] implements the basic synthesis procedure based on best first search described in Section~\ref{Exploration}.
\item[\mdseries\textsc{Blacklist}] implements the pruning of the search space based on a manually compiled black list provided in Table~\ref{fig:manual_blacklist}. We refer to Section~\ref{Black list} for more details.
\item[\mdseries\textsc{Template}] implements the double best first search introduced in Section~\ref{Templates}. As you probably recall, the procedure first looks for a \emph{template} featuring at most \lstinline?nof_comp? higher-order components and at most \lstinline?nof_hol? holes and as soon as such a template is found the procedure falls back on the \textsc{Plain} variant up to a certain depth using only the first-order components.
\end{description}

For each exploration strategy, we instantiated the cost function with three of the cost functions described in Section~\ref{Cost functions}, that is with \textit{nof-nodes}, \textit{nof-nodes-simple-type} and \textit{no-same-component}. We refer back to the corresponding section for more details.

We exercised the nine different variants of our synthesis procedure on a benchmark of $23$ programs over lists, mostly taken from related work or standard functional programming assignments.
Table~\ref{fig:gianttable} summarises the running times. The first three columns summarise the runtimes of the nine variants of out synthesis procedure when the synthesiser is given 36 to 37 components. Columns four to six contain, for each variant, the slowdown with respect to the minimum running time for the respective benchmark. The last three columns show the speedup we obtain if we leave only 18 to 19 components in the library.
Table~\ref{fig:nofnodestable} lists the benchmarks along with the size of the solution generated by each of the nine variants, expressed in number of nodes.

\paragraph{Components} In the first three columns of Table~\ref{fig:gianttable} all benchmarks except for \lstinline?nth? share the same set of components, listed in Table~\ref{fig:library-components}. For the synthesis of individual benchmarks appearing in the library as components we took the corresponding component out of the library.
In the last three columns of Table~\ref{fig:gianttable}, in order to meet the needs of all benchmarks, we used four different sets of $19$ components.

\paragraph{Timeout} Programs are enumerated only up to a timeout based on the number of programs that have been analysed so far. For the exploration strategies \textsc{Plain} and \textsc{BlackList} the execution had been stopped after examining $2500000$ programs (with or without holes). The exploration strategy \textsc{Template} was restricted to generate templates with at most $2$ higher-order components and at most $5$ holes, the depth of the first-order search was limited to $10$ calls to the \textsc{Plain} procedure. For the cost function \textit{nof-nodes} this corresponds to circa \SI{4}{min}.

\subsection{Results}\label{Table summary}
Two variants of our synthesis procedure were able to synthesise all $23$ benchmarks in the presence of $36$ to $37$ library components, all variants synthesised at least $18$ benchmark programs within the time limit. $78\%$ of the benchmarks were synthesised within \SI{1}{s} using \textsc{BlackList} as the exploration strategy and \textit{nof-nodes-simple-type} as the cost function.

The variants that use the \textsc{BlackList} exploration strategy can synthesise the most number of benchmarks: for two cost functions they generate all $23$ benchmark programs within the time limit, for the cost function \textit{no-same-component} they fail to synthesise \lstinline?enumFromTo?. They synthesise half of the benchmarks in under \SI{0.2}{s} on average and $17$ benchmark programs in under \SI{1}{s}.

The variants that use the \textsc{Plain} exploration strategy can synthesise from $21$ to $22$ benchmark programs depending on the cost function. They are on average $8$ times slower than the variant that combines the \textsc{BlackList} exploration strategy with the \textit{nof-nodes-simple-type} cost function. However, $15$ benchmarks are synthesised less than $3$ times slower and for $3$ of them the running times are actually lower. In the case of \lstinline?enumTo? the solution found by the other variants, \lstinline?enumTo n = enumFromTo (succ zero) n?, contains a pattern forbidden by the black list we used to prune the search space. The other two benchmarks have very short, simple solutions for which the overhead of checking every program against the black list is not balanced out by a substantial pruning of the search space.

The variants of our synthesis procedure that use the \textsc{Template} exploration strategy can synthesise only $18$ to $19$ benchmark programs within the time out. Moreover, they are on average $1680$ times slower than the variant that uses the \lstinline?BlackList? exploration strategy combined with the \textit{nof-nodes-simple-type} cost function. However, this value is pushed up by the benchmark \lstinline?factorial?. For half of the $18$ benchmarks all variants can synthesise this value is less than $20$ and $15$ of them are no more than $90$ times slower than the variant that combines \textsc{BlackList} with \textit{nof-nodes-simple-types}.
\input{gianttable}

\section{Automatic black list}\label{Black list generation}
We also used our system to generate an automatic black list based on the identity function. We chose not to generate the polymorphic identity function. As during pruning we are ignoring types, holes and input variables, the programs that would have been generated for the polymorphic identity function are also generated for the identity over any specific type. We chose to generate programs corresponding to the identity function over integers, lists of integers and lists of lists of integers.

To that end, we first used the synthesis procedure that combines the \textsc{Plain} exploration strategy with the \textit{nof-nodes} cost function to synthesise the first $8$ programs of type \lstinline?Int?, respectively \lstinline?List Int? or \lstinline?List (List Int)?. For this step we provided only the constructors \lstinline?con, nil, succ, zero? to the synthesiser. We paired each synthesised program with itself to generate and input-output example.

As a second step, for each of the following goal types
\begin{lstlisting}[style=plain]
Int -> Int
List Int -> List Int
List (List Int) -> List (List Int)
\end{lstlisting}
we used the synthesis procedure that combines the \textsc{Plain} exploration strategy with the \textit{nof-nodes} cost function to synthesise the first $100$ programs that satisfy the $8$ input-output examples of the corresponding type generated in the previous step. This time we provided the synthesiser with the $37$ components listed in Table~\ref{fig:library-components}.

After removing duplicates and the classical program corresponding to the identity function, that is \lstinline?id x = x?, we got $212$ black list patterns. Section~\ref{Automatic black list} reviews the quality of the generated black list.


\subsection{Results}\label{Automatic black list}
We were able to automatically synthesise $300$ programs corresponding to the identity function for three different types using automatically generated input-output examples in under \SI{2}{s}. Because of their incremental nature, we need $8$ automatically synthesised input-output examples as opposed to the $2$-$3$ manual ones that would have been enough. Below that number there is no list of lists of integers that contains something but \lstinline?nil? or no list of length two. This implies that synthesis using automatically synthesised input-output examples is slower than synthesis using manual ones.

For the evaluation of the benchmarks we preferred compiling a manual black list mainly because of three reasons: 
\begin{enumerate}
\item All programs in the automatically generated black list correspond to the identity function.
\item Many automatically generated black list programs are unnecessary. For example, \lstinline?append (append nil nil) _? and \lstinline?concat (append nil _)? are not needed if the black list already contains \lstinline?append nil _?.
\item The automatically generated programs are all closed programs and as such they are too concrete. For example, instead of \lstinline?foldNatNat max _ zero?, \lstinline?foldNatNat const _ zero? and \lstinline?foldNatNat drop _ zero? we could just have the one program \lstinline?foldNatNat _ _ zero? that generalises all the programs with the idea that folding over the integer $0$ is the same as taking the initial value, no matter which function is used for folding.
\end{enumerate}

The first two points can be addressed with small modifications to the experimental set up: generate \lstinline?nil?, \lstinline?zero?, \lstinline?undefined? and other constants as well for the first and prune the black list after or during generation for the second.
The third point is way more complex. Partial evaluation of programs with holes could help to some extent, but at the end it is about the ability to abstract and generalise over programs.


\section{Factors affecting runtime}\label{Factors affecting runtime}
The search space is of exponential nature and depends on many factors: most notably the number of library components and the size of the solution to be synthesised. In the remainder of this section we look at these and other factors and their influence on the runtime.

\subsection{Number of components}
One well known factor that exponentially affects the runtime is the number of components provided to the synthesiser.

With 19 components we could synthesise all benchmarks with all procedures except the ones using the \textsc{Template} exploration strategy. With 37 components only two variants find all programs.

In particular, with $37$ components, even if we provide \lstinline?enumTo?, the synthesis benchmark \lstinline?enumFromTo? times out for seven procedures out of nine, whereas with only $19$ components this number is reduced to three.
Interestingly, if we provide a $38$th component, namely \lstinline?drop?, then six procedures succeed in the synthesis of \lstinline?enumFromTo?. This has a very simple explanation: \lstinline?enumFromTo? has a smaller solution that uses \lstinline?drop?.

Since our synthesis procedures expand holes in a type aware manner, the number of components with the same type has an even higher impact on the running time than just the number of components. For example, if we add a constant of a new type \lstinline?Foo? to the library, the running time will not increase much, because there are not many places, where we can use this component without causing a type error. On the contrary, if we would add another function from lists to lists like \lstinline?tail? or \lstinline?inits?, depending on the goal type we could have a considerable slowdown. 

\subsection{Size of the solution}
\TODO{If you have time, redo the graphics in latex, or at least find a way to move trend line in the legend}
\begin{figure}[p]
    \centering
    \includegraphics[width=0.95\textwidth]{time_vs_nof_nodes.eps}
    \caption{Average running time of the variants of the synthesis procedure depending on the number of nodes of the solution.}
    \label{fig:runtime_vs_nof_nodes}
\end{figure}
In the previous sections we mentioned a second factor: the size of the solution to be synthesised. Figure~\ref{fig:runtime_vs_nof_nodes} shows that the average running time for all nine variants of the synthesis procedure depends exponentially on the number of nodes of the solution found. This goes along with the intuition that a bigger program is more difficult to synthesise.

For example, if we have $n$ possibilities to generate a program consisting of one node, that is \lstinline!?x! where we have $n$ possibilities to instantiate the hole \lstinline!?x!, then we will have $n^2$ possibilities to generate a program with three nodes, that is \lstinline!?$x_1$ ?$x_2$! where we have $n$ possibilities to instantiate each hole.




In our simple intuitive explanation of the exponential dependency of the synthesis time on the size of the solution we completely ignored the contribution of types to search space pruning.

\subsection{Cost functions}
Cost functions are an instrument to prioritize some programs over others and as such have an impact on the running time. We extensively evaluated three of the cost functions described in Section~\ref{Cost functions}: \textit{nof-nodes}, \textit{nof-nodes-simple-type} and \textit{no-same-component} with three different exploration strategies. In the following we will see how they affect the runtime and which programs they prefer.

\begin{description}
\item[nof-nodes] prioritises shorter programs and prefers input variables to library components to holes, under the hypothesis that smaller programs generalise better to the examples. However, this cost function gives the same cost to the following two programs.
\begin{lstlisting}[style=plain]
head [List Int -> List Int] (nil [List Int -> List Int]) ?xs
map Int Int succ ?xs
\end{lstlisting}
It seems therefore natural that paired with the \textsc{Plain} strategy it usually leads to higher running times than other cost functions.

\item[nof-nodes-simple-type] additionally penalises arrow types appearing in type applications. We can see it in the solution for \lstinline?length?. Two of the synthesis procedures that use this cost function find the larger solution
\begin{lstlisting}
length [X] xs
    = sum (map [X] [Int] (const [Int] [X] (succ zero)) xs)
\end{lstlisting}
instead of the smaller
\begin{lstlisting}
length [X] xs
    = foldr [X] [Int] (const [Int -> Int] [X] succ) zero xs,
\end{lstlisting}
because the second one contains an arrow type in a type application.

The impact on the runtime of this cost function is comparable to the introduction of pruning based on black lists. This has to do with the fact that polymorphic functions that apply in many cases but are rarely needed, like \lstinline?const? and \lstinline?flip?, tend to instantiate their type variables with long arrow types. In the \textsc{BlackList} exploration strategy those programs are filtered by the black list, the \textit{nof-nodes-simple-type} cost function assigns them a higher cost because of their types.

\item[no-same-component] prioritises smaller programs with simpler types and additionally penalises the use of the same component more than once. The hope is that without having to inspect programs that take a long time to evaluate like \lstinline?enumTo (prod (enumTo (prod xs)))?, running times will sink. Against expectations, this is usually not the case. The reason could be that the synthesis procedures that use this cost function examine many larger programs that do not contain any type applications, like \lstinline!enumTo (mul (succ (div n m)) (succ ?x))!.
\end{description}

\subsection{Stack vs Queue expansion}
As already mentioned in Section~\ref{Search space}, we have two open questions in our best first search:
\begin{enumerate}[a.]
\item what program to expand next
\item which hole of this program to expand first
\end{enumerate}
In the previous section we addressed the first question with different cost functions. In this section we focus on the second one.

Among all possible heuristics to determine which hole of the least-cost program to expand next, we chose to discuss two. In the first one the open holes of a program are organised as a stack, as opposed to the second one, where the open holes are kept in a queue.

Organising the open holes of a program as a stack leads to the expansion of the holes from left to right. To give some intuition, we provide a derivation of \lstinline?mapAdd? showing the stack of open holes on the right of the program, where \lstinline?xs? represents the input list and \lstinline?n? the amount of the increment.
\begin{lstlisting}[style=plain]
(?$x_0$, [$x_0$]) $\longrightarrow$
(?$x_1$ ?$x_2$, [?$x_1$, ?$x_2$]) $\longrightarrow$
(?$x_3$ ?$x_4$ ?$x_2$, [?$x_3$, ?$x_4$, ?$x_2$])) $\longrightarrow$
(map [Int] ?$x_4$ ?$x_2$, [?$x_4$, ?$x_2$]) $\longrightarrow$
(map [Int] (?$x_5$ ?$x_6$) ?$x_2$, [?$x_5$, ?$x_6$, ?$x_2$]) $\longrightarrow$
(map [Int] (add ?$x_6$) ?$x_2$, [?$x_6$, ?$x_2$]) $\longrightarrow$
(map [Int] (add n) ?$x_2$, [?$x_2$]) $\longrightarrow$
(map [Int] (add n) xs, [])
\end{lstlisting}
Left-to-right expansion often leads to faster synthesis, because leftmost holes usually have more constraints on their type. Consider the program \lstinline!?$x_3$ ?$x_4$ ?$x_2$! from the derivation of \lstinline??. We know more about \lstinline!?$x_3$! than about \lstinline!?$x_2$!: the first one must be a function that takes two arguments of some type and returns a list of integers, whereas the second hole could be anything. Furthermore, the instantiation of \lstinline!?$x_3$! with \lstinline?map [Int]? imposes some constraints on the types of \lstinline!?$x_4$! and \lstinline!?$x_2$!.

Keeping the open holes of a program in a queue leads to the expansion of the hole with the smallest depth first. This could be useful to control the depth of a program, but in practice it has a substantial drawback. Consider again the derivation of \lstinline?mapAdd?. The first three steps are the same, but in the program \lstinline!?$x_3$ ?$x_4$ ?$x_2$! we would now try to expand the hole \lstinline!?$x_2$!, that we have absolutely no information about. Every library component and every input variable are valid instantiations of this hole. Thus, this expanding strategy leads to a higher branching factor and explores many superfluous programs like \lstinline!?$x_3$ ?$x_4$ map! and \lstinline!map (?$x_5$ foldr) xs!.

We used the stack-based expansion strategy throughout all runtime evaluations of the benchmarks.


\subsection{Examples}
Another factor that greatly impacts on performance is the choice and the number of provided input-output examples. As our procedure evaluates every closed program it synthesises on at least the first input-output example, we must make sure that the first input-output example is
\begin{enumerate}[a.]
\item small enough, so that also undesirable programs like \lstinline?enumTo (prod (enumTo (prod xs)))? do not get stuck or run out of memory trying to construct a list with $479001600$ elements, which happens already for the at first sight innocent input \lstinline?[2,2,3]?;
\item expressive enough to rule out many programs, so that there is no need to fall back on the other, often bigger, input-output examples.
\end{enumerate}
Clearly, using as few and as small input-output examples as possible has a positive effect on performance. On the other side, too few and too general input-output examples can lead to the synthesis of the wrong program, that is a program that satisfies all provided input-output examples but that does not generalise in the expected way. This was especially a problem with \lstinline?enumFromTo? and \lstinline?member?. For example, if we provided \lstinline?enumFromTo? only with examples that result in a list of length three, we got the program that simply concatenated the first input with its successor with the second input.
\begin{lstlisting}[style=plain]
enumFromTo m n
    <> con [Int] m (con [Int] (succ m) (con [Int] n (nil [Int])))
\end{lstlisting}
If we provided \lstinline?enumFromTo? only with examples starting with $1$, the synthesised solution was just a call to \lstinline?enumTo? with the second input variable as argument or, depending on the components we gave, the program corresponding to \lstinline?enumTo n?.
\begin{lstlisting}[style=plain]
enumFromTo m n
    <> foldNatNat [List Int] (con [Int]) (nil [Int]) n
\end{lstlisting}
And for the two examples \lstinline?enumFromTo 1 2? and \lstinline?enumFromTo 2 4? that we carefully chose so that the output lists had different lengths and so that the first arguments were different, we got the program that completely ignores the second argument, as it assumes that the length of the resulting list is the successor of the first argument.
\begin{lstlisting}[style=plain]
enumFromTo m n
    <> con [Int] m (map [Int] [Int] (b_add m) (enumTo m))
\end{lstlisting}

\subsection{Blacklist}
The search space abounds of superfluous programs that are equivalent to smaller ones. In Section~\ref{Black list} we introduced a way to leverage this inconvenience: pruning based on black lists. This approach allows us not to explore further programs that will surely lead to a solution bigger than the optimal one, like \lstinline!append [X] (nil [X]) ?$xs$!, or not lead to a solution at all, like \lstinline!(head [?$X_1$ -> ?$X_2$ -> $X_3$] (nil [?$X_1$ -> ?$X_2$ -> $X_3$])) ?$x_1$ ?$x_2$!.

A longer black list allows to prune more superfluous programs and sinks considerably the number of programs our synthesis procedure needs to consider before finding a solution. However, in our implementation black list pruning is extremely expensive. Each element of the black list is matched against every subterm of every program with holes that is generated. That is, there is a trade-off between the length of the black list and the gain in performance that we can get.

Figure~\ref{fig:manual_blacklist} shows the black list  we used to evaluate the benchmarks. We manually compiled it combining unwanted patterns often seen in the search space with some carefully chosen automatically generated identity functions. We also added some rapidly increasing functions. For example, following program computing tetration\footnote{Tetration, written as $^{n}a$ or $a \uparrow\uparrow n$, is the operation defined as \[\underbrace{a^{a^{.^{.^a}}}}_{n \text{ times}}.\]} represents a problem for our evaluator.
\begin{lstlisting}[style=plain]
tetration a n =
    foldNat [Int] (foldNat [Int] (mul a) 1) 1 n
\end{lstlisting}


\begin{longtable}{l l}
\lstinline?append nil? & \lstinline?head (enumFromTo _ _)?\\
\lstinline?append _ nil? & \lstinline?head (enumTo _)?\\
\lstinline?add _ zero? & \lstinline?head (map _ _)?\\
\lstinline?add zero? & \lstinline?head nil?\\
\lstinline?div _ zero? & \lstinline?head (replicate _ _)?\\
\lstinline?div _ (succ zero)? & \lstinline?isNil nil?\\
\lstinline?div zero? & \lstinline?length (con _ _)?\\
\lstinline?div (succ zero)? & \lstinline?length (enumFromTo _ _)?\\
\lstinline?foldNat _ _ zero? & \lstinline?length (enumTo _)?\\
\lstinline?foldNat succ zero? & \lstinline?length (map _ _)?\\
\lstinline?foldNatNat (foldNatNat _ _ _)? & \lstinline?length nil?\\
\lstinline?foldNatNat _ _ zero? & \lstinline?length (reverse _)?\\
\lstinline?isZero zero? & \lstinline?map _ nil?\\
\lstinline?max zero zero? & \lstinline?maximum nil?\\
\lstinline?mul (succ zero)? & \lstinline?not (not _)?\\
\lstinline?mul _ (succ zero)? & \lstinline?prod (con _ nil)?\\
\lstinline?mul _ zero? & \lstinline?prod (con zero _)?\\
\lstinline?mul zero? & \lstinline?prod nil?\\
\lstinline?sub _ zero? & \lstinline?prod (reverse _)?\\
\lstinline?sub zero? & \lstinline?replicate zero?\\
\lstinline?concat nil? & \lstinline?reverse (con _ nil)?\\
\lstinline?const _ _? & \lstinline?reverse (map _ (reverse _))?\\
\lstinline?enumFromTo (succ zero)? & \lstinline?reverse nil?\\
\lstinline?enumTo zero? & \lstinline?reverse (reverse _)?\\
\lstinline?enumTo (prod _)? & \lstinline?sum (con _ nil)?\\
\lstinline?flip _ _ _? & \lstinline?sum nil?\\
\lstinline?foldl _ _ nil? & \lstinline?sum (reverse _)?\\
\lstinline?foldr con nil? & \lstinline?tail (con _ nil)?\\
\lstinline?foldr _ _ nil? & \lstinline?tail (enumFromTo _ _)?\\
\lstinline?head (con _ _)? & \lstinline?tail nil?\\
\caption{Manually compiled black list patterns used for evaluation in the \textsc{BlackList} exploration strategy.\label{fig:manual_blacklist}}
\end{longtable}

In Table~\ref{fig:gianttable} we see that the runtime profits the most from the introduction of black list pruning when we use the cost function \textit{nof-nodes}.
The running time drops less significantly if we use other cost functions. A possible explanation of this behaviour could be the fact that other cost functions give a higher cost to those programs that are filtered with our black list.

We could also empirically see that pruning using black lists is very helpful in the presence of polymorphic functions that apply in many cases but are rarely needed, for example \lstinline?flip?, \lstinline?const? or \lstinline?uncurry?. Forbidding a fully applied \lstinline?flip?, \lstinline?const? or \lstinline?uncurry? has a comparable effect on performance to taking those components out of the library. However, since we are not taking those components out of the library, we are still able to synthesise functions that need them.

\subsection{Templates}
In Table~\ref{fig:gianttable} we see that the synthesis procedures that use the \textsc{Template} exploration strategy fail more often to find a solution within the timeout. Moreover, even if they find a solution, they tend to be $10$ times slower than the other synthesis procedures, \lstinline?length?, \lstinline?member?, \lstinline?replicate? and \lstinline?reverse? being an exception.

The main reason for this slowdown resides in our implementation. In particular, in the successor rules we presented in Section~\ref{Templates}. 
Consider following derivation of a template for \lstinline?replicate?, where \lstinline?X? represent the input type variable, \lstinline?n? is the first argument and \lstinline?x? is the second. The list on the right of each program shows the type of its open holes.
\begin{lstlisting}[style=plain]
(?$x_0$,       [?$x_0$ :: List X]) $\longrightarrow$
(?$x_1$ ?$x_2$,     [?$x_1$ :: ?Y ->  List X, ?$x_2$ :: ?Y]) $\longrightarrow$
($\underline{?x_1}$ ?$x_2$,      [?$x_2$ :: ?Y]) $\longrightarrow$
($\underline{?x_1}$ (foldr [?$Z_1$] [?$Z_2$]),   [])
\end{lstlisting}
Note that the only thing we can do with \lstinline!?$x_1$! is to close it, because in our library there is no higher-order component that takes only one argument. On the other hand, \lstinline!?$x_2$! can be instantiated with every higher-order function of the library, because closing \lstinline!?$x_1$! does not constrain its type in any way.
This means that, before having a chance to explore a sensible template with $4$ leaves like \lstinline!foldl [?X] [?Y] ?f ?init ?xs!, the synthesiser must explore up to a certain depth many non that sensible but smaller templates like \lstinline!?x (foldr [?X] [?Y])!.

The solutions synthesised by the synthesis procedures that use the \textsc{Template} exploration strategy tend to contain more higher-order components and in two cases are surprisingly long. In Table~\ref{fig:nofnodestable} we can see that two variants of our synthesis procedure synthesise a program with $13$ nodes for \lstinline?factorial?, whereas all other variants find one with only $5$ nodes.

Despite of those drawbacks, the \textsc{Template} exploration strategy is still interesting: it is more resilient to the choice of input-output examples compared to the other two. For example, if we provide a slightly larger input-output example for \lstinline?dropmax?, six variants of our synthesis procedure run out of memory, whereas the three variants that use the \textsc{Template} exploration strategy still find the solution in under \SI{8}{s}.

\subsection{Unknown factors}
Individual results show that there must be other factors influencing the runtime. Take, for example, \lstinline?enumFromTo?, \lstinline?stutter? and \lstinline?nth?. All three of them have a solution with exactly $13$ nodes, but their runtimes differ at least by an order of magnitude for the synthesis procedures that do not time out on \lstinline?stutter?. What does make \lstinline?nth? generate in less than \SI{1}{s}, \lstinline?stutter? a hundred times slower and \lstinline?enumFromTo? to time out in most of the cases?

\section{Synthesised solutions}
Most of the synthesised solutions are precisely the ones we would have written by hand. For some programs different variants of the synthesis procedure find two different valid programs of the same size. For example, for \lstinline?replicate? we find following two solutions.
\begin{lstlisting}
replicate [X] n x
    = map Int [X] (const [X] Int x) (enumTo n)
\end{lstlisting}
\begin{lstlisting}
replicate [X] n x
    = foldNat [List X] (con [X] x) (nil [X]) n
\end{lstlisting}

For the few benchmarks that can use \lstinline?foldl? and \lstinline?foldr? interchangeably, like \lstinline?concat?, \lstinline?maximum? and \lstinline?sum?, different variants find different programs. The different variants of the synthesis procedure do not show clear preference for the one or the other. They can use \lstinline?foldr? for one of such programs and \lstinline?foldl? for the other.

Interesting is the case of \lstinline?multfirst? and \lstinline?multlast?, where following two solutions are found.
\begin{lstlisting}
multfirst [X] xs
    = map [X] [X] (const [X] [X] (head [X] xs)) xs
\end{lstlisting}
\begin{lstlisting}
multfirst [X] xs
    = replicate [X] (length [X] xs) (head [X] xs)
\end{lstlisting}
We omit the analogous solutions for \lstinline!multlast! for brevity.
The different synthesis procedures show a clear preference for the one or the other. For example, all synthesis procedures using the \textsc{Template} exploration strategy seem to prefer the use of the higher-order \lstinline?map? to the first-order \lstinline?replicate?. This has to do with the depth of the first-order search. The search from a particular template (in this case the template with no higher-order functions) times out before reaching programs with three components. On the other hand, the search starting from the template \lstinline!map [?Y] [X] (const [?Y] [X] ?$x_1$) ?$x_2$! succeeds within the timeout.

The preference of the \textsc{Template} exploration strategy for solutions containing higher-order functions leads to unexpectedly large programs. For example, one of the solutions for \lstinline?factorial? is
\begin{lstlisting}
factorial n
    = prod (foldr [List Int] [List Int]
        (foldl [List Int] [Int] (const [List Int] [Int]))
        (enumTo n)
        (nil [List Int]))
\end{lstlisting}
instead of the much simpler \lstinline?prod (enumTo n)?. Note that since we are folding over an empty list, the two programs are completely equivalent.

There is a tendency to represent the constant integer $1$ as \lstinline?prod (nil [Int])? instead of \lstinline?succ zero?. And even if we forbid with a black list the patterns
\begin{lstlisting}
enumFromTo (succ zero) _
prod nil
\end{lstlisting}
the synthesis procedure with the \textsc{BlackList} exploration strategy still finds a way to express \lstinline?enumTo? using \lstinline?enumFromTo?: It simply falls back to 
\begin{lstlisting}
enumTo n
    = enumFromTo (div n n) n.
\end{lstlisting}
Of course, if we take the component \lstinline?enumFromTo? out of the library we can generate the desired program
\begin{lstlisting}
enumTo n
    = foldNatNat [List Int] (con [Int]) (nil [Int]) n.
\end{lstlisting}

Small programs are not always efficient. For example, for \lstinline?enumFromTo? we find the solution
\begin{lstlisting}
enumFromTo m n
    = con [Int] m (foldNat [List Int] (tail [Int]) (enumTo n) m)
\end{lstlisting}
that corresponds to generating a list from $1$ to the second input and then dropping the first part of the list. The more efficient solution
\begin{lstlisting}
enumFromTo m n
    = con [Int] m (map [Int] [Int] (add m) (enumTo (sub n m)))
\end{lstlisting}
is larger and thus it is generated only if we take \lstinline?foldNat? out of the library.

Sometimes the solution found by the synthesiser suggested other benchmarks we could try to synthesise. For example, after examining the aforementioned solution for \lstinline?enumFromTo? we realized that \lstinline?drop? can be implemented as
\begin{lstlisting}
drop [X] n xs
    = foldNat [List X] (tail [X]) xs n
\end{lstlisting}
Analogously, a "wrong" solution for \lstinline?member? turned out to be a clever implementation of \lstinline?isEven?, namely \lstinline?foldNat not true n?. Folding over an integer is similar to recursion over that integer. In this case the base case of the recursion is \lstinline?true? and in the inductive case we negate \lstinline?isEven (n-1)?.\\
Another unexpectedly clever solution is due to the absence of a polymorphic equality function. We only had equality over integers, thus the benchmark \lstinline?member? is not polymorphic but has the type \lstinline?Int -> List Int -> Bool?. This allowed the synthesiser to generate, along with the expected solution
\begin{lstlisting}
member n xs
    = not (is_nil [Int] (filter [Int] (eq n) xs)),
\end{lstlisting}
a special version that makes use of the fact that the product of a list is $0$ if the list contains at least one $0$ and that two numbers are equal if their difference is $0$.
\begin{lstlisting}
member n xs
    = is_zero (prod (map [Int] [Int] (sub n) xs))
\end{lstlisting}
This works in our implementation because our built-in integers can have negative values.


\section{Comparison to related work}
We compare our synthesis procedure that uses the \textsc{Blacklist} exploration strategy combined with the \textit{nof-nodes-simple-type} cost functions with the state-of-the-art tools reported in Chapter~\ref{ch:relatedwork}. The results are summarised in Table~\ref{fig:comparisontable}, where for each tool we provide the specification size (expressed in number of examples for example-based tools and in AST nodes for \textsc{Synquid}) and the runtime.

Since the running times were taken from the respective papers and were not run on the same machine, we cannot directly compare performance. However, the case of \lstinline?droplast?, where \textsc{$\lambda^2$} takes around \SI{300}{s} and our tool only \SI{0.06}{s}, cannot be explained only by the difference in the hardware. Providing the right components, in this case \lstinline?reverse? and \lstinline?tail?, helps the synthesis tool to find a solution faster.

Another thing that impedes direct comparison of the running time is that the other tools generate a richer class of programs. All of them are capable of generating recursive functions and most of them have support for conditionals and pattern matching, whereas the target language of our tool includes only application of components and input variables. On the other hand, components can encode well-known recursion patterns. For example, programs that use the component \lstinline?foldNat? naturally translate to a recursive program, as we see from the example of \lstinline?isEven?.
\begin{lstlisting}[style=plain]
isEven n = foldNat not true n
\end{lstlisting}
\begin{lstlisting}[style=plain]
isEven n = match n with
  | 0 -> true
  | 1 + m -> not (isEven m)
\end{lstlisting}

It might be a consequence of the simplicity of our target language, but as we can see in Table~\ref{fig:comparisontable}, our tool needs less input-output examples to synthesise the benchmarks than the other example-based tools. \textsc{Synquid} relies on a different specification that requires a higher level of expertise, which makes direct comparison difficult.

The number of provided components also changes across the tools. With $36$ to $37$ components, we provide the largest library to our tool. On the second place, \textsc{Escher} uses a library of $23$ components to evaluate all benchmarks. Other tools handle less components.

Considering that our tool is just standard type-aware best-first enumeration, it is surprising that only four benchmarks show a considerably worse (about two orders of magnitude) performance than the state-of-the-art.

\begin{table}
\pgfplotstabletypeset[
    col sep=comma,
	column type=l,
	every head row/.style={
		before row={%
			\toprule
			% program name
		    %& % base
			& \multicolumn{2}{c}{Our tool}
			& \multicolumn{2}{c}{\textsc{Synquid}}
			& \multicolumn{2}{c}{$\lambda^2$}
			& \multicolumn{2}{c}{\textsc{Escher}}
			& \multicolumn{2}{c}{\textsc{Myth}}\\
			\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}
		},
		after row=\midrule,
	},
	every last row/.style={
		after row=\bottomrule},
	columns/name/.style = {string type,column name=name},
	columns/nof-examples-tamandu/.style = {column type=r,column name=spec},
	columns/time-tamandu/.style = {fixed,column type=r,column name=time},
	columns/spec-size-synquid/.style = {column type=r,column name=spec},
	columns/time-synquid/.style = {fixed,column type=r,column name=time},
	columns/nof-examples-lambda/.style = {column type=r,column name=spec},
	columns/time-lambda/.style = {fixed,column type=r,column name=time},
	columns/nof-examples-escher/.style = {column type=r,string type,column name=spec},
	columns/time-escher/.style = {fixed,column type=r,column name=time},
	columns/nof-examples-myth/.style = {column type=r,column name=spec},
	columns/time-myth/.style = {fixed,column type=r,column name=time},
]{comparison.dat}
\caption{Comparison of our tool with the state-of-the-art. For our tool, $\lambda^2$ and \textsc{Myth} the \emph{spec} column shows the number of examples, for \textsc{Synquid} it shows the specification size in AST nodes. For all tools the \emph{time} columns show the runtime in seconds. The cells corresponding to benchmarks that were not tested with the respective tool are left empty.\label{fig:comparisontable}}
\end{table}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
