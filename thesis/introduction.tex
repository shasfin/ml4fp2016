\lstset{style=plain}

\chapter{Introduction}\label{ch:introduction}
The task of program synthesis is to automatically synthesise\footnote{That is why, program synthesis is sometimes referred to as automatic programming.} a program that implements some sort of specification: a logical formula that completely describes the desired input-output behaviours, or as in the case we consider, a couple of concrete examples of those behaviours.  That is to say, we assume a list of inputs paired toghether with corresponding expected outputs. The goal is, then, to find a program that correctly extrapolates those behaviours outside of the given input range.  Compared to providing a precise logical specification, this is an intuitive and simple way to specify programs and makes synthesis more accessible to users with a lower level of expertise.

When solving programming tasks, human programmers invariably rely on prior knowledge in form of computational patterns.  Well-known patterns are typically reflected by libraries of reusable components (subprograms).  For example, the \lstinline!map! higher-order function expresses the transformation of each element of a list according to a given mapping.  The more general combinator \lstinline!foldr! captures primitive recursion on lists: \lstinline!foldr f init xs! is equivalent to \lstinline!g xs!, where \lstinline!g! is defined by the following recursive scheme\footnote{Through the thesis we use an improvised Haskell-like syntax.}:
\begin{lstlisting}[style=plain]
g [] = init
g (x:xs) = f x (g xs)
\end{lstlisting}

Our main goal is to assess how well the computational knowledge encoded in purely functional components can be reused by an automatic synthesiser.  In order to simplify the matter, we assume that the provided components are expressive enough to implement any desired behaviour solely via function application.  The synthesis of lambda expressions, recursive functions, or conditionals is not considered.  On the other hand, we place no restrictions on the used components (beyond being pure functional), which in theory allows~any desired function to be synthesised.

\section{Program synthesis work}\label{Background}
The past $50$ years of research approached program synthesis from various points of view from related fields.  Early methods \cite{Manna:1980:DAP:357084.357090} were based on automatic theorem proving and the Curry–Howard correspondence.  A complete logical specification of a program is translated into a theorem and a proof of this theorem is then translated into a program satisfying the specification. A drawback of these approaches is that a high level of mathematical maturity is required to formulate a specification as a logical formula.

A more accessible way to specify a program is by giving a finite number of input-output examples that the synthesised program must satisfy.  In this setting, two main approaches have been most popular.  The first one analyses the input-output examples to derive a set of relations that capture them, and then transforms this descritption into a program \cite{Summers:1977:MLP:321992.322002,Kitzelmann:2009:AIF:1530575.1530582,Jha:2010:OCP:1806799.1806833}.  Even though the techiques are quite interesting, they need much more advancement.

The second one is based on program enumeration \cite{LambdaSquarePaper,EscherPaper,MythPaper}, and became popular as the processor speed increased.  Good results were obtained by restricting the target programs to a specific domain \cite{Fischer:2003:ASG:967842.967845,Frigo98fftw:an,Thies2002,Gulwani:2011:ASP:1926385.1926423,Gulwani:2011:SGC:1993498.1993505}. Recently a system parametrised by a context-free domain-specific languages~\cite{Perelman:2014:TS:2594291.2594297} was presented, which gives a lot of flexibility.  Another way to restrict the problem is to require the user for additional clues, as in \textsc{Sketch} \cite{Solar-Lezama:2006:CSF:1168857.1168907}, where the programmer provides the high-level structure of the program, while the synthesiser fills in the low-level details.  Another interesting aspect of \textsc{Sketch} is that it combines/frames program enumeration with constraint-satisfaction, for which it relies on off-the-shelf SAT and SMT solvers.

Recently, type theory and program verification also entered the synthesis scene \cite{LeonPaper,DBLP:journals/corr/InalaQLS15,Kuncak:2010:CFS:1806596.1806632}.  Systems like \cite{LambdaSquarePaper,MythPaper} (as well as our work) actively use type signatures to prune the search space.  More advanced types are even used as a specification \cite{SynquidPaper}.  Interestingly, \cite{Frankle:2016:EST:2837614.2837629} gave a type theoretic interpretation to example-based systems.

\section{Problem statement}\label{Problem}

The synthesis procedure we define and evaluate in this thesis aims to synthesise straight-line purely applicative functional programs specified by input-output examples. We use a simple enumerate-and-test approach. In order to avoid errors due to bad typing, we enumerate only well-typed programs. We rely on a large library of first- and higher-order components reflecting common computational patterns.
The synthesiser should compose a program from library components that agrees with the given input-output examples and generalises well to unseen examples.

For example, consider we want to generate \lstinline!replicate!, the function that takes an integer \lstinline!n! and an element \lstinline!x! of any type and returns the list \lstinline![x, x, $\ldots$, x]! of length \lstinline!n!. A straight-line purely applicative functional solution composed from standard first- and higher-order components would be:
\begin{lstlisting}[style=plain]
replicate n x = map (const x) (enumTo n)
\end{lstlisting}
In the above program, \lstinline!map! is the higher-order function that applies its first argument, a function, to every element of its second argument, a list; \lstinline!const! is the function that takes two arguments and always returns the first one; \lstinline!enumTo! is the function that takes an integer \lstinline!m! and returns the list \lstinline![1, 2, $\ldots$, m]!.
The above program encodes the following insight: in order to generate a list consisting of \lstinline!n! copies of \lstinline!x!, we can first generate a list of length \lstinline!n!, in this case \lstinline![1, 2, $\ldots$, n]!, and then transform each element of this list into \lstinline!x!.

In contrast to other systems based on enumeration \cite{MythPaper, LambdaSquarePaper}, we do not target recursive programs or programs containing lambda expressions, conditionals or pattern matching. However, those restrictions theoretically do not limit the set of functions we can express, since adding suitable higher-order components\footnote{For example, the $S, K, I$ combinators introduced by Schönfinkel in \cite{Schonfinkel1924}.} to the library makes it possible to express all computable functions.

In practice, we can mimic popular recursive patterns with suitable library components. For example, the program \lstinline!p n = foldNat f init n! can be translated into the following recursive program.
\begin{lstlisting}[style=plain]
p 0 = init
p n = f (p (n-1))
\end{lstlisting}
Instantiating \lstinline!init! with \lstinline![]! and \lstinline!f! with \lstinline!(x:)! leads to a solution for \lstinline!replicate! corresponding to the recursive program:
\begin{lstlisting}[style=plain]
replicate 0 x = []
replicate n x = x:(replicate (n-1) x)
\end{lstlisting}

Analogously, the component \lstinline!foldNatNat! mimics the recursive pattern:
\begin{lstlisting}[style=plain]
p 0 = init
p n = f n (p (n-1))
\end{lstlisting}
This common pattern is used in the recursive definitions of \lstinline!enumTo!, \lstinline!sumUnder! and \lstinline!factorial!.

We are interested in studying how an inductive synthesis algorithm can apply this knowledge in a synthesis task. In particular, we are interested how a library of first- and higher-order components can guide and speed up the synthesis process.
To that end, we implement in OCaml a prototype\footnote{\TODO{Link to the code?}} of the synthesis procedure we define in Chapter~\ref{ch:definitions}. The main contribution of this thesis is the extensive evaluation of our synthesis procedure and the exploration of the search space. The experiments and the findings are presented in Chapter~\ref{ch:evaluation}.

The rest of the thesis is structured as follows. In Chapter~\ref{ch:definitions} the top-down synthesis procedure is introduced and formally defined. Chapter~\ref{ch:implementation} describes how to turn this synthesis procedure into a synthesis tool written in OCaml. In Chapter~\ref{ch:relatedwork} we shortly review four closely related synthesis tools: \textsc{Synquid} \cite{SynquidPaper}, $\lambda^2$ \cite{LambdaSquarePaper}, \textsc{Escher} \cite{EscherPaper} and \textsc{Myth} \cite{MythPaper}. In Chapter~\ref{ch:evaluation} we present the results of the empiric evaluation. Finally, Chapter~\ref{ch:conclusions} draws the conclusions and outlines the possibilities for future work.
