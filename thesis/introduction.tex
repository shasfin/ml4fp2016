\lstset{style=plain}

\chapter{Introduction}\label{ch:introduction}
In this thesis, we investigate a method for automatic program synthesis.  Program synthesis strives to automatically synthesise programs given some sort of specification of their behaviour.   For example, suppose we want to synthesise the function \lstinline!replicate! that takes a number $n$ and an element $x$ of any type and returns the list $[x, \dots, x]$ made of $n$ copies of $x$.

We could specify the \lstinline!replicate! function by providing a logical formula that completely describes the relation between inputs and outputs: \[ \forall n, x \ldotp \exists y \ldotp \; \texttt{replicate} \; n \; x = y \land (\mathrm{length}(y) = n \land (\forall z \in y \ldotp z = x)). \]  Then, a logic-based program synthesier would take such a formula and try to deduce an implementation of \lstinline!replicate! that satisfies it.

Providing logical specifications, however, can be quite difficult, and we will be interested in a more natural alternative: specification by example.  Here, the user has some function in mind and provides only a few input-output examples of its behaviour.  From those few examples, the synthesiser has to induce an implementation of the function that the user has in mind.

For our \lstinline!replicate! function, we could give the following specification (in an improvised Haskell-like syntax, which we will use through the thesis):
\begin{lstlisting}[style=plain]
replicate 0 'A' = []
replicate 1 'A' = ['A']
replicate 2 'A' = ['A', 'A']
replicate 3 'A' = ['A', 'A', 'A']
\end{lstlisting}
The sythesiser then has to ``guess'', or rather, extrapolate the behavour in the examples to unseen inputs.  This guess could for example use recursion:
\begin{lstlisting}[style=plain]
replicate 0 x = []
replicate n x = x:(replicate (n - 1) x)
\end{lstlisting}

However, synthesising a recursive definition directly is a rather difficult and unstructured problem: there are too many choices of how to invoke the function recursively.  A human programmer rarely attacks such problems directly, but relies on prior knowledge of restricted computational patterns.  Moreover, well-known patterns are widely implemented as reusable components (subprograms) and grouped into libraries.

For example, the computational pattern of replacing every element $x$ in a list according to a map $x \mapsto \texttt{f} \; x$ is captured by the \lstinline!map! higher-order function:
\[ [x_1, \dots, x_n] \xmapsto{\texttt{map f}} [\texttt{f} \; x_1, \dots, \texttt{f} \; x_n]. \]
Another, more general, pattern is the accumulation of the values of a list along a binary operation \lstinline!f! (\lstinline!`f`! in infix), as captured by \lstinline!foldr!:
\[ [x_1, \dots, x_n] \xmapsto{\texttt{foldr f} \; x_{n+1}} x_1 \texttt{ `f` } x_2 \texttt{ `f` } \dots \texttt{ } x_n \texttt{ `f` } x_{n+1}. \] 

%% as captured by the \lstinline!foldr! function: $\texttt{foldr} \; f \; init \; xs$ is equivalent to $\texttt{g} \; xs$, where \lstinline!g! is defined by primitive recursion:
%% \begin{lstlisting}[style=plain]
%% g [] = init
%% g (x:xs) = f x (g xs)
%% \end{lstlisting}

To illustrate how computational patterns are reused by humans, consider how to implement the \lstinline!replicate! function without recursion (or \lstinline!foldr!):
\begin{lstlisting}[style=plain]
replicate n x = map (const x) (enumTo n)
\end{lstlisting}
Here, \lstinline!const! takes two arguments and always returns the first one; \lstinline!enumTo! takes an integer $n$ and returns the list $[1, 2, \ldots, n]$.  The solution encodes the insight: to generate a list consisting of $n$ copies of $x$, one can first generate an any list of length $n$, and then map each element to the given $x$.  This leads us to the question: can a synthesiser produce such ``insightful'' programs?

\section{Problem statement}

The main goal of the thesis is to investigate whether the computational knowledge encoded in components can help an automatic synthesiser, in analogy of how a human reuses known patterns in order to solve such tasks.  In particular, we investigate whether one can quickly synthesise solutions to basic algorithmic tasks in terms of standard library components.  Our main hypothesis is that standard components capture widely useful patterns that one can use to find short and simple solution programs.

Towards this goal, we develop an examples-based synthesis algorithm, not tailored to a specific set of components.  This allows one to easily expand the ``computational knowledge'' of the synthesiser simply by adding new components.  To simplify the matter, we focus on the synthesis of purely functional programs without any lambda expressions, explicit recursion or conditionals (i.e., only function application is allowed).  This restriction is inessential as richer constructs can be easily simulated by applications of suitable higher-order components.  But importantly, it allows for a clean synthesis algorithm that focuses on how to combine components effectively.

%% For example, consider we want to generate \lstinline!replicate!, that is the function that takes an integer \lstinline!n! and an element \lstinline!x! of any type and returns the list consisting of \lstinline!n! copies of \lstinline!x!. We expect our synthesiser to output the program:
%% \begin{lstlisting}[style=plain]
%% replicate n x = map (const x) (enumTo n)
%% \end{lstlisting}
%% In the above program, \lstinline!const! is the function that takes two arguments and always returns the first one; \lstinline!enumTo! is the function that takes an integer \lstinline!m! and returns the list \lstinline![1, 2, $\ldots$, m]!.
%% The synthesised solution encodes the insight: in order to generate a list consisting of \lstinline!n! copies of \lstinline!x!, one can first generate a list of length \lstinline!n!, in this case \lstinline![1, 2, $\ldots$, n]!, and then map each element to \lstinline!x!.

\section{Existing work}\label{Background}
The past $50$ years of research approached program synthesis from various points of view.  For example, early methods \cite{Manna:1980:DAP:357084.357090} were based on automatic theorem proving and the relation between proofs and programs (the Curryâ€“ Howard correspondence).  They convert a logical specification of a program into a theorem, find a proof of this theorem, and then extract a program from the proof.  Such methods are mainly limited by the performance of the employed theorem prover (which, unfortunately, is not much at present).  A drawback of these approaches is that a high level of mathematical maturity is required to provide the needed logical specification.

A more accessible way to specify a program is by giving a finite number of input-output examples that the synthesised program must satisfy.  In this setting, two main approaches are most popular.  The first one analyses the input-output examples to derive a set of relations that capture them, and then transforms this description into a program \cite{Summers:1977:MLP:321992.322002,Kitzelmann:2009:AIF:1530575.1530582,Jha:2010:OCP:1806799.1806833}.  Even though the techniques are quite interesting, they need much more advancement.  The second one is based on program enumeration \cite{LambdaSquarePaper,EscherPaper,MythPaper}, and became more popular as the processor speed increased.

Good results for the second approach were obtained by restricting the target programs to a specific domain \cite{Gulwani:2011:ASP:1926385.1926423,Gulwani:2011:SGC:1993498.1993505}. Recently a generic system for synthesis in domain-specific languages~\cite{Perelman:2014:TS:2594291.2594297} was presented.  This system gives a lot of flexibility to make the synthesis more tractable by employing more restrictive languages.  Another way to restrict the problem is to require the user for additional clues, as in \textsc{Sketch} \cite{Solar-Lezama:2006:CSF:1168857.1168907}, where the user sketches the high-level structure of the program, while the synthesiser fills in the low-level details.  To achieve efficiency, \textsc{Sketch} combines program enumeration with constraint-satisfaction, for which it uses off-the-shelf SAT/SMT solvers.

Recently, type theory and program verification also entered the synthesis scene \cite{LeonPaper,DBLP:journals/corr/InalaQLS15,Kuncak:2010:CFS:1806596.1806632,Frankle:2016:EST:2837614.2837629}.  Systems like \cite{LambdaSquarePaper,MythPaper,SynquidPaper} actively use type signatures to prune the search space.  This is quite reasonable, as type information is easy to provide and usually readily available.  Also, type-based pruning is essential in our setting, because a large number of library components can often be combined in a small number of ways due to typing.  That is why, our synthesis algorithm also falls into the type-based pruning category.

\section{Contributions}
In this thesis we study whether program synthesis can benefit from access to common computational patterns.  In particular, we investigate whether a library (of first and higher-order components) can guide and speed up the synthesis process.  Towards this end we make the following contributions:

\begin{enumerate}
\item We develop a basic synthesis algorithm for purely functional programs based on exhaustive enumeration combined with type-based pruning.

\item We propose a couple of heuristics to guide the search in a best-first manner, and also how to automatically blacklist certain useless branches.

\item We develop a prototype implementation of our algorithm in OCaml, and perform an extensive evaluation over a library of 37 components.

\item We analyse the results of the evaluation and compare it with reported results from state-of-the-art program synthesis tools.
\end{enumerate}  

Our evaluation indicates that for simple algorithmic problems, our basic algorithm combined with a good enough library of components performs on par with much more sophisticated state of the art algorithms.
