\lstset{style=plain}

\chapter{Related Work} \label{ch:relatedwork}

In this chapter we look at four state-of-the-art tools closely related to our work. They all synthesise functional programs, are based on inductive enumeration and use type information to restrict the search space. Since simple types are too ambiguous to specify a program, the tools we present either choose to complement type information with input-output examples or resort to more complex and more expressive types that can actually act as a specification, as for example the \emph{refinement types} from \cite{SynquidPaper}.

\section{\mdseries\textsc{Synquid}}

In \cite{SynquidPaper} \textsc{Synquid} is proposed. The code can be found online\footnote{https://bitbucket.org/nadiapolikarpova/synquid} and there is the possibility to try it in the browser.
This tool uses \emph{refinement types} (types decorated with logical predicates) to prune the search space and to specify programs. SMT-solvers are used to satisfy the logical predicates appearing in the types.\\
Refinement types were already successfully used for verification. In particular, the tool builds upon the liquid types framework \cite{LiquidTypes}. However, it proposes a new procedure for type inference (called modular refinement type reconstruction), which thank to its modularity scales better than other existing inference procedures for refinement types. Programs can therefore be type checked even before they are put together.

This tool targets a language that includes lambda expressions, pattern matching, structural recursion, conditionals and fixpoint.
The user can define custom functions and inductive datatypes that can be passed to the synthesiser as components.

A program is specified by providing a type signature. For example, the synthesis goal \lstinline!replicate! can be specified as follows.
\begin{lstlisting}[style=plain]
n : Nat -> x : $\alpha$ -> {List $\alpha$ | len $\nu$ = n}
\end{lstlisting}
This is a dependent function type that denotes functions that, given a natural number $n$ and an $x$ of type $\alpha$, return a list of $\alpha$ of length $n$. Here $\nu$ is a special logical value variable that in this case denotes the runtime return value of the functions and \lstinline!len! is a measure function defined over lists.

This form of specification can be a disadvantage, since it is not that accessible to users with a lower level of expertise as input-output examples. It is not always easy to see which measure function for a custom datatype will lead to the most simple and intuitive specification.
On the other hand, refinement types allow to express programs that manipulate data structures with non-trivial universal and inductive invariants in a concise way. This allows to synthesise programs on sorted lists, unique lists, binary search trees, heaps and red-black trees.

This tool synthesises simple programs over lists and integers in under \SI{0.4}{s}. It can also handle more complex benchmarks that are out of the scope of this thesis, such as different sorting algorithms and manipulations of data structures with complex invariants. Various sorting algorithms over lists and trees are synthesised in under \SI{5}{s}. The synthesis of the most complex benchmark, the balancing of a red-black tree, takes up to \SI{20}{s}.

In contrast to our tool, the number of components provided to the synthesiser for evaluation is small.

\section{$\lambda^2$}
The tool proposed in \cite{LambdaSquarePaper} is called $\lambda^2$ and generates its output in $\lambda$-calculus with algebraic types and recursion. The target language also includes $7$ higher-order combinators such as \lstinline!map!, \lstinline!fold! and \lstinline!filter! and a flexible set of primitive operators and constants.

The user specifies the desired program providing only input-output examples. No particular knowledge is required from the user, as was demonstrated using randomly generated input-output examples. The goal type is inferred from the examples.

The synthesis algorithm is a combination of inductive generalisation, a limited form of deduction and enumerative search.
First, it generates \emph{hypotheses} in a type-aware manner, that is programs with free variables such as \lstinline!$\lambda$x. map ?f x! where \lstinline!?f! is a placeholder for an unknown program to be synthesised.
Then deduction in form of hand-coded rules about the higher-order combinators is used either to refute a hypothesis or infer new input-output examples to guide the synthesis of missing functions. For example, the hypothesis \lstinline!$\lambda$x. map ?f x! will be refuted if the length of the input list does not match the length of the output length.
Enumerative search is used to enumerate candidate programs to fill in the missing parts of hypotheses. Hypotheses and candidate programs are organised in a priority queue and, at each point of the search, the least-cost candidate is picked.

This tool is able to synthesize programs manipulating recursive data structures like lists, trees and nested data structures such as lists of lists and trees of lists.
It synthesises all benchmark programs in under 7~minutes. Half of the benchmarks is synthesised in under \SI{0.43}{s}. However, the synthesis of \lstinline!droplast!, the program that drops the last element of a list, takes up to \SI{320}{s}. The program that removes duplicates from a list, the program that drops the smallest elements of each list of a list of lists and the program that inserts a tree under each leaf of another tree take more than \SI{100}{s} to synthesise.

Unlike \textsc{Synquid} and our work, this tool can only use the $7$ hard-coded higher-order combinators. The extension of the set of higher-order combinators with own functions is not easily supported.


\section{\mdseries\textsc{Escher}}

In \cite{EscherPaper} \textsc{Escher} is presented. This tool targets a simple untyped purely functional language consisting of constants, input variables, conditionals and library components applied to all of their arguments, including a special component \lstinline!self! referring to the program being synthesised. This last component is used to synthesise recursive programs.

The user specifies the desired program as a \emph{closed} set of input-output examples. That is, for each input-output example, all examples needed to evaluate every recursive call must be present. For example, if we want to specify \lstinline!replicate! as
\begin{lstlisting}[style=plain]
replicate 2 'a' = ['a','a'],
\end{lstlisting}
we also need to provide the input-output examples for the possible recursive calls, that is
\begin{lstlisting}[style=plain]
replicate 1 'a' = ['a']
replicate 0 'a' = [].
\end{lstlisting}
This is necessary because recursive programs are evaluated using the input-output examples as an oracle. However, it is not always easy for an inexperienced user to provide such a set.

The search is goal-directed. Programs are associated with value vectors, that is the vector of the outputs of the program on the inputs from the input-output examples. Programs sharing the same value vectors are considered equivalent, that is the search space is pruned based on observational equivalence.
The algorithm alternates between two phases: forward search and conditional inference. During forward search programs are inductively enumerated by adding new components to already synthesised programs. During conditional inference a novel data structure, the \emph{goal graph}, is used to detect when two synthesised programs can be joined by a conditional statement. The alternation between the two phases is guided by a heuristic.

This tool is able to synthesise recursive programs, including tail recursive, mutually recursive and divide-and-conquer. It synthesises all benchmarks in under \SI{11}{s} and all but three benchmarks in under \SI{1}{s}. The benchmarks include programs on integers such as \lstinline!fibonacci! and \lstinline!isEven!, programs on lists such as \lstinline!compress! and \lstinline!insert! and programs on trees such as \lstinline!nodes-at-level! and \lstinline!count-leaves!.

Like our work, this tool can handle a flexible set of components. For example, a set of $23$ components was used to evaluate all benchmarks. However, there was no higher-order component among them.

\section{\mdseries\textsc{Myth}}

\begin{itemize}
\item name and paper
\item target language (subset of OCaml, no polymorphic types, but it could easily be extended to them)
\item specification (type signature and a closed set of input-output examples)
\item what do they do
\item benchmarks and timing
\item number of components unknown.
\end{itemize}

\TODO{Write this section\\}
Myth (Osera). Like mine, requires type and I/O-examples. Refinement tree.
\begin{enumerate}
\item What is the specification?
A type signature, the components and a list of input-output examples.
\item What is the target language?
subset of OCaml.
pattern matching, recursion, higher-order functions in typed programming languages. Can synthesise higher-order functions, programs using higher-order functions and work with large algebraic datatypes.
ML-like language with algebraic data types, match, top-level function definitions and explicitly recursive functions.
\item What can they do well and fast? How fast?
Recursive programs with pattern matching. It's very fast, many programs are synthesised in around 0.1~s. It can also generate larger programs (75 AST nodes) in reasonable time (3~s for calculating the set of free variables in an untyped lambda-calculus).
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
To generate recursive functions, they also need a closed set of examples, so that a recursive call to the function being synthesised can be answered by an input-output example. They also require relatively many examples. They use a relatively large context, but they do not say how big it is.
Lacks support richer types like products and polymorphic types.
\item What do they do?
The tool in \cite{MythPaper} is called \textsc{Myth} and uses not only type information but also input-output examples to restrict the search space. The special data structure used to hold this information is the \emph{refinement tree}. This system can synthesize higher-order functions, programs that use higher order functions and work with large algebraic data types.\\
There is an ML-like type system that incorporates input-output examples. Two pieces: a \emph{refinement tree} and an enumerative search.\\
Two major operations: refine the goal type and the examples (push them down in the refinement tree) and guess a term of the right type that matches the examples (for one of the nodes of the refinement tree).\\
Proof-search-based. Modify typing tules so that they "push" exmples towards the leaves of the typing derivation trees. Permits to evaluate candidate terms early in the search process.\\
Incorporate the input-output examples in the type system. non-deterministic specification of the synthesis problem, the goal is to find a term that has a valid typing derivation.\\
Alternate between two major operations: refine the constraints (goal type and examples) and guess a term of the goal type that is consistent with the constraints. Guessing: rule out ill-types terms and terms that are not structurally recursive. To avoid other bad programs, guess only programs in $\beta$-normal form, that is that cannot be reduced further. Match refinement: try to guess a match-statement. First, try to guess a term of an algebraic type to match against. Based on the constructors, send the examples to the branches. So, there are two subgoals in refined worlds. Recursive functions: the input-output examples, interpreted as a partial function, serve as approximation of the function being synthesised.
\end{enumerate}





%Leon (can bring it, it's deductive, so it's different than the others. It also targets functional programs. No, I have nothing to compare. The benchmark is too different.) \cite{LeonPaper}
%\begin{enumerate}
%\item What is the specification?
%Input-output relations (including examples), pre- and postconditions.
%\item What is the target language?
%Several recursion schemas (only terminating programs), components, pattern matching
%\item What can they do well and fast? How fast?
%The good thing is that they generate verified software. And it's interactive, the user can control the structure if he wants to.
%\item What is the difficulty? What can they not generate (or take a long time)? How much time?
%
%\item What do they do?
%Deductive synthesis, counterexample-guided.
%That's from the verification side: the point is to deliver \emph{verified} software that satisfies some specifications such as assertions, pre-conditions and post-conditions.
%\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
