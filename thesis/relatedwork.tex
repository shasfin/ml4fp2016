\chapter{Related Work} \label{ch:relatedwork}

Here discuss only synthesis of functional programs. Input-output examples are an intuitive and easy way to specify programs. Types are good to prune the search space, but simple types are not enough to specify a program. So the research went in two directions: on one side, there was the need to do something to the I/O-examples to make the search more efficient, on the other side more complex and expressive types that can act as a specification, for example the \emph{refinement types} from \cite{SynquidPaper}. Lately, there was the idea that one can automatically generate those ty[pes from I/O-examples, to have both the advantages of an intuitive and easy specification and the research done on type systems, liquid types and something like that.


Let's start. My 5 papers, organize some information about them.
\begin{itemize}
\item Synquid (Nadia) put the replicate example if you can (should not be that difficult). Not that "user friendly". Lambda, conditionals, recursion, components. Synthesis starting from a partial program possible. Fast, good for sorting. It is possible to download the tool (put link), try it online and there is even an emacs-mode for it.
\begin{enumerate}
\item What is the specification?
The refinement type of the desired program, that is a type decorated with logical predicates. Can bring the replicate example.
\item What is the target language?
Haskell, I think. I saw lambda abstractions and recursion. Can generate and use higher-order components. You can specify own datatypes and own components.
Pattern matching, structural recursion, ability to use and generate polymorphic higher-order functions, reasoning about universal and recursive properties of data structures.\\
The Synquid language has lambda expressions, pattern matching, conditional and fixpoint.
\item What can it do well and fast? How fast?
Most advanced benchmark: generate various sorting algorithms for data structures with complex invariants (search trees, heaps, balanced trees). This is out of scope of my synthesis procedure.
For the "easy" benchmarks (what I have) everything under 0.4~s. For more complicated stuff like sorting and tree insertion under 5 seconds. For most complicated stuff (red-black trees) under 20~s.
\item What is the difficulty? What can they not generate (or take a long time to generate)? How much time do they need?
It is not always easy for an inexperienced user to specify a program and to find the right 'measure' function for a datatype.\\
They need up to 20~s to generate balance over red-black trees. They usually don't give more than 5 components and 6 measure functions over the needed data types.\\
The specification is quite big compared to the synthesised program, half of the programs the specification is one third of the generated program or more.
\item What do they do?
In \cite{SynquidPaper} \textsc{Synquid} is proposed.
Refinement types (types decorated with logical predicates) are used to prune the search space. SMT-solvers are used to satisfy the logical predicates. The key is the new procedure for type inference (called modular refinement type reconstruction), which thank to its modularity scales better than other existing inference procedures for refinement types. Programs can therefore be type checked even before they are put together.
\end{enumerate}
\item Lambda square (Feser). How would you specify replicate? Give an idea of how it is generated. User friendly, as only I/O-examples need to be specified, type is reconstructed automatically.
\begin{enumerate}
\item What is the specification?
I/O-examples
\item What is the target language?
Their synthesis algorithm targets a functional programming language that permits higher-order functions, combinators like map, fold and filter, pattern-matching, recursion, and a flexible set of primitive operators and constants. Actually, lambda calculus with algebraid data types and recursion.
\item What can it do well and fast? How fast?
Generating programs over nested structures like trees of lists, lists of lists and lists of trees. They generate the half of the benchmarks in under 0.43~s.
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
Only 7 higher-order combinators and not much more first-order components.\\
They use relatively many examples (between 3 and 12, mostly 4 to 6).\\
They need up to 320~s to generate \lstinline?droplast?. Other benchmarks that take more than 100~s to synthesise are removing duplicates from a list, inserting a tree under each leaf of another tree and dropping the smallest number in a list of lists.
\item What do they do?
Inductive generalization, deduction, enumerative search.
First, generate \emph{hypotheses} (that is, programs with free variables like \lstinline!$\lambda$x. map ?f x! where \lstinline!?f! is a placeholder for an unknown program that needs to be generated) in a type-aware manner (the type is inferred from the I/O-examples). Then deduction based on the semantics of the higher-order combinators is used either to quickly refute a hypothesis or infer new I/O-examples to guide the synthesis of missing functions. Best-first enumerative search is used to enumerate candidate programs to fill in the missing parts of hypotheses.\\
The tool proposed in \cite{LambdaSquarePaper} is called $\lambda^2$ and generates its output in $\lambda$-calculus with algebraic types and recursion.
%If the tool does not time out on a set of input-output examples, it generates the least-cost program.
The user specifies the desired program providing input-output examples.  
No particular knowledge is required from the user, as was demonstrated using random input-output examples.
The examples are inductively generalized in a type-aware manner to a set of hypotheses (programs that possibly have free variables).
The key idea are the hard-coded deduction rules used to prune the search space depending on the semantics of some of the higher-order combinators (map, fold, filter and a few others).
Deduction is also used to infer new input-output examples in order to generate the programs needed to fill in the holes in the hypotheses.
This tool is able to synthesize programs manipulating recursive data structures like lists, trees and nested data structures such as lists of lists and trees of lists.
The tool is able to synthesise all benchmark programs in under 7~minutes.
\end{enumerate}
\item Escher (Kincaid). User friendly, as untyped and only I/O-examples need to be specifies. Powerful (recursion, special if-then-else, components) Goal graph.
\begin{enumerate}
\item What is the specification?
I/O-examples. Oracle simulating interaction with the user.
\item What is the target language?
Recursion, special treatment for conditionals, components. That's really all they have: either apply a component to its arguments (including component \lstinline?self? referring to the program being generated for recursion), a constant, an input variable or a conditional. Programming language is untyped. Components may be higher-order.
\item What can they do well and fast? How fast?
Synthesise recursive programs (tail recursive, divide-and-conque, mutually recursive). In the evaluation, they give 23 components to all benchmarks, none of them is higher-order. Can generate all benchmarks in under 11~s, most of them in under 1~s.
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
The user must give a \emph{closed} example set, that is for each example, there must be another example that can be used for a recursive call.
\item What do they do?
Forward search: inductive enumeration, add a new component to an already synthesised program.
Conditional inference: use the goal graph to see if you can join to synthesised programs by a conditional statement.
A heuristic guides the alternation between forward search and conditional inference.
Programs are associated with value vectors. Search space is also pruned based on \emph{observational equivalence}, that is programs with equivalent value vectors are treated as equivalent programs.\\
Can be formalised as a non-deterministic transition system over configurations (triples consisting of a set of synthesised programs, a goal graph and a list of input-output examples) with six transition rules: an initial rule to start the search, a terminate rule to terminate the search and four synthesis rules (one for forward search, two for conditional split and one to ask for new input-output examples to evaluate a recursive call). The recursive calls are answered by the oracle.\\
Rule scheduling is added to turn this into a practical system (different heuristics).\\
In \cite{EscherPaper} \textsc{Escher} is presented, an inductive synthesis algorithm that learns a recursive procedure from input-output examples provided by the user. \note{The user must provide a "closed" set of examples, otherwise recursion cannot be handled properly} The target language is untyped, first-order and purely functional.
The algorithm is parametrized by components that can be instantiated differently to suit different domains.
The approach combines enumerative search and conditional inference. The key idea is to use a special data structure, a \emph{goal graph}, to infer conditional branches instead of treating \texttt{if-then-else} as a component.
Observational equivalence is also used to prune the search space. Programs with the same value vectors (output of the program when applied to the inputs of the input-output examples) are considered equivalent and only one of them is synthesized.
An implementation of the tool was tested on a benchmark consisting of recursive programs \note{(including tail-recursive, divide-and-conquer and mutually recursive programs)} drawn from functional programming assignments and standard list and tree manipulation programs.
For all examples the same fixed set of components was used.
The tool is able to synthesize all of them quickly. \note{There is very little information on how many input-output examples were needed to synthesize the benchmarks and how difficult it is for a non-experienced user to come up with a "closed" set of examples.}
\end{enumerate}
\item Myth (Osera). Like mine, requires type and I/O-examples. Refinement tree.
\begin{enumerate}
\item What is the specification?
A type signature, the components and a list of input-output examples.
\item What is the target language?
pattern matching, recursion, higher-order functions in typed programming languages. Can synthesise higher-order functions, programs using higher-order functions and work with large algebraic datatypes.
ML-like language with algebraic data types, match, top-level function definitions and explicitly recursive functions.
\item What can they do well and fast? How fast?
Recursive programs with pattern matching. It's very fast, many programs are synthesised in around 0.1~s. It can also generate larger programs (75 AST nodes) in reasonable time (3~s for calculating the set of free variables in an untyped lambda-calculus).
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
To generate recursive functions, they also need a closed set of examples, so that a recursive call to the function being synthesised can be answered by an input-output example. They also require relatively many examples. They use a relatively large context, but they do not say how big it is.
Lacks support richer types like products and polymorphic types.
\item What do they do?
The tool in \cite{MythPaper} is called \textsc{Myth} and uses not only type information but also input-output examples to restrict the search space. The special data structure used to hold this information is the \emph{refinement tree}. This system can synthesize higher-order functions, programs that use higher order functions and work with large algebraic data types.\\
There is an ML-like type system that incorporates input-output examples. Two pieces: a \emph{refinement tree} and an enumerative search.\\
Two major operations: refine the goal type and the examples (push them down in the refinement tree) and guess a term of the right type that matches the examples (for one of the nodes of the refinement tree).\\
\end{enumerate}


\end{itemize}






%Leon (can bring it, it's deductive, so it's different than the others. It also targets functional programs. No, I have nothing to compare. The benchmark is too different.) \cite{LeonPaper}
%\begin{enumerate}
%\item What is the specification?
%Input-output relations (including examples), pre- and postconditions.
%\item What is the target language?
%Several recursion schemas (only terminating programs), components, pattern matching
%\item What can they do well and fast? How fast?
%The good thing is that they generate verified software. And it's interactive, the user can control the structure if he wants to.
%\item What is the difficulty? What can they not generate (or take a long time)? How much time?
%
%\item What do they do?
%Deductive synthesis, counterexample-guided.
%That's from the verification side: the point is to deliver \emph{verified} software that satisfies some specifications such as assertions, pre-conditions and post-conditions.
%\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
