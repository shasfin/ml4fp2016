\lstset{style=plain}

\chapter{Related Work} \label{ch:relatedwork}

In this chapter we look at four state-of-the-art tools closely related to our work. They all synthesise functional programs, are based on inductive enumeration and use type information to restrict the search space. Since simple types are too ambiguous to specify a program, the tools we present either choose to complement type information with input-output examples or resort to more complex and more expressive types that can actually act as a specification, as for example the \emph{refinement types} from \cite{SynquidPaper}.

\section{\mdseries\textsc{Synquid}}

In \cite{SynquidPaper} \textsc{Synquid} is proposed. The code can be found online\footnote{https://bitbucket.org/nadiapolikarpova/synquid} and there is the possibility to try it in the browser.
This tool uses \emph{refinement types} (types decorated with logical predicates) to prune the search space and to specify programs. SMT-solvers are used to satisfy the logical predicates appearing in the types.\\
Refinement types were already successfully used for verification. In particular, the tool builds upon the liquid types framework \cite{LiquidTypes}. However, it proposes a new procedure for type inference (called modular refinement type reconstruction), which thank to its modularity scales better than other existing inference procedures for refinement types. Programs can therefore be type checked even before they are put together.

This tool targets a language that includes lambda expressions, pattern matching, structural recursion, conditionals and fixpoint.
The user can define custom functions and inductive datatypes that can be passed to the synthesiser as components.

A program is specified by providing a type signature. For example, the synthesis goal \lstinline!replicate! can be specified as follows.
\begin{lstlisting}[style=plain]
n : Nat -> x : $\alpha$ -> {List $\alpha$ | len $\nu$ = n}
\end{lstlisting}
This is a dependent function type that denotes functions that, given a natural number $n$ and an $x$ of type $\alpha$, return a list of $\alpha$ of length $n$. Here $\nu$ is a special logical value variable that in this case denotes the runtime return value of the functions and \lstinline!len! is a measure function defined over lists.

This form of specification can be a disadvantage, since it is not that accessible to users with a lower level of expertise as input-output examples. It is not always easy to see which measure function for a custom datatype will lead to the most simple and intuitive specification.
On the other hand, refinement types allow to express programs that manipulate data structures with non-trivial universal and inductive invariants in a concise way. This allows to synthesise programs on sorted lists, unique lists, binary search trees, heaps and red-black trees.

This tool synthesises simple programs over lists and integers in under \SI{0.4}{s}. It can also handle more complex benchmarks that are out of the scope of this thesis, such as different sorting algorithms and manipulations of data structures with complex invariants. Various sorting algorithms over lists and trees are synthesised in under \SI{5}{s}. The synthesis of the most complex benchmark, the balancing of a red-black tree, takes up to \SI{20}{s}.

In contrast to our tool, the number of components provided to the synthesiser for evaluation is small.

\section{$\lambda^2$}
\TODO{Write this section\\}
Lambda square (Feser). How would you specify replicate? Give an idea of how it is generated. User friendly, as only I/O-examples need to be specified, type is reconstructed automatically.
\begin{enumerate}
\item What is the specification?
I/O-examples
\item What is the target language?
Their synthesis algorithm targets a functional programming language that permits higher-order functions, combinators like map, fold and filter, pattern-matching, recursion, and a flexible set of primitive operators and constants. Actually, lambda calculus with algebraid data types and recursion.
\item What can it do well and fast? How fast?
Generating programs over nested structures like trees of lists, lists of lists and lists of trees. They generate the half of the benchmarks in under 0.43~s.
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
Only 7 higher-order combinators and not much more first-order components.\\
They use relatively many examples (between 3 and 12, mostly 4 to 6).\\
They need up to 320~s to generate \lstinline?droplast?. Other benchmarks that take more than 100~s to synthesise are removing duplicates from a list, inserting a tree under each leaf of another tree and dropping the smallest number in a list of lists.
\item What do they do?
Inductive generalization, deduction, enumerative search.
First, generate \emph{hypotheses} (that is, programs with free variables like \lstinline!$\lambda$x. map ?f x! where \lstinline!?f! is a placeholder for an unknown program that needs to be generated) in a type-aware manner (the type is inferred from the I/O-examples). Then deduction based on the semantics of the higher-order combinators is used either to quickly refute a hypothesis or infer new I/O-examples to guide the synthesis of missing functions. Best-first enumerative search is used to enumerate candidate programs to fill in the missing parts of hypotheses.\\
The tool proposed in \cite{LambdaSquarePaper} is called $\lambda^2$ and generates its output in $\lambda$-calculus with algebraic types and recursion.
%If the tool does not time out on a set of input-output examples, it generates the least-cost program.
The user specifies the desired program providing input-output examples.  
No particular knowledge is required from the user, as was demonstrated using random input-output examples.
The examples are inductively generalized in a type-aware manner to a set of hypotheses (programs that possibly have free variables).
The key idea are the hard-coded deduction rules used to prune the search space depending on the semantics of some of the higher-order combinators (map, fold, filter and a few others).
Deduction is also used to infer new input-output examples in order to generate the programs needed to fill in the holes in the hypotheses.
This tool is able to synthesize programs manipulating recursive data structures like lists, trees and nested data structures such as lists of lists and trees of lists.
The tool is able to synthesise all benchmark programs in under 7~minutes.
\end{enumerate}

\section{\mdseries\textsc{Escher}}
\TODO{Write this section}
Escher (Kincaid). User friendly, as untyped and only I/O-examples need to be specifies. Powerful (recursion, special if-then-else, components) Goal graph.
\begin{enumerate}
\item What is the specification?
I/O-examples. Oracle simulating interaction with the user.
\item What is the target language?
Recursion, special treatment for conditionals, components. That's really all they have: either apply a component to its arguments (including component \lstinline?self? referring to the program being generated for recursion), a constant, an input variable or a conditional. Programming language is untyped. Components may be higher-order.
\item What can they do well and fast? How fast?
Synthesise recursive programs (tail recursive, divide-and-conque, mutually recursive). In the evaluation, they give 23 components to all benchmarks, none of them is higher-order. Can generate all benchmarks in under 11~s, most of them in under 1~s.
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
The user must give a \emph{closed} example set, that is for each example, there must be another example that can be used for a recursive call.
\item What do they do?
Forward search: inductive enumeration, add a new component to an already synthesised program.
Conditional inference: use the goal graph to see if you can join to synthesised programs by a conditional statement.
A heuristic guides the alternation between forward search and conditional inference.
Programs are associated with value vectors. Search space is also pruned based on \emph{observational equivalence}, that is programs with equivalent value vectors are treated as equivalent programs.\\
Can be formalised as a non-deterministic transition system over configurations (triples consisting of a set of synthesised programs, a goal graph and a list of input-output examples) with six transition rules: an initial rule to start the search, a terminate rule to terminate the search and four synthesis rules (one for forward search, two for conditional split and one to ask for new input-output examples to evaluate a recursive call). The recursive calls are answered by the oracle.\\
Rule scheduling is added to turn this into a practical system (different heuristics).\\
In \cite{EscherPaper} \textsc{Escher} is presented, an inductive synthesis algorithm that learns a recursive procedure from input-output examples provided by the user. \note{The user must provide a "closed" set of examples, otherwise recursion cannot be handled properly} The target language is untyped, first-order and purely functional.
The algorithm is parametrized by components that can be instantiated differently to suit different domains.
The approach combines enumerative search and conditional inference. The key idea is to use a special data structure, a \emph{goal graph}, to infer conditional branches instead of treating \texttt{if-then-else} as a component.
Observational equivalence is also used to prune the search space. Programs with the same value vectors (output of the program when applied to the inputs of the input-output examples) are considered equivalent and only one of them is synthesized.
An implementation of the tool was tested on a benchmark consisting of recursive programs \note{(including tail-recursive, divide-and-conquer and mutually recursive programs)} drawn from functional programming assignments and standard list and tree manipulation programs.
For all examples the same fixed set of components was used.
The tool is able to synthesize all of them quickly. \note{There is very little information on how many input-output examples were needed to synthesize the benchmarks and how difficult it is for a non-experienced user to come up with a "closed" set of examples.}
\end{enumerate}

\section{\mdseries\textsc{Myth}}
\TODO{Write this section\\}
Myth (Osera). Like mine, requires type and I/O-examples. Refinement tree.
\begin{enumerate}
\item What is the specification?
A type signature, the components and a list of input-output examples.
\item What is the target language?
pattern matching, recursion, higher-order functions in typed programming languages. Can synthesise higher-order functions, programs using higher-order functions and work with large algebraic datatypes.
ML-like language with algebraic data types, match, top-level function definitions and explicitly recursive functions.
\item What can they do well and fast? How fast?
Recursive programs with pattern matching. It's very fast, many programs are synthesised in around 0.1~s. It can also generate larger programs (75 AST nodes) in reasonable time (3~s for calculating the set of free variables in an untyped lambda-calculus).
\item What is the difficulty? What can they not generate (or take a long time)? How much time do they need?
To generate recursive functions, they also need a closed set of examples, so that a recursive call to the function being synthesised can be answered by an input-output example. They also require relatively many examples. They use a relatively large context, but they do not say how big it is.
Lacks support richer types like products and polymorphic types.
\item What do they do?
The tool in \cite{MythPaper} is called \textsc{Myth} and uses not only type information but also input-output examples to restrict the search space. The special data structure used to hold this information is the \emph{refinement tree}. This system can synthesize higher-order functions, programs that use higher order functions and work with large algebraic data types.\\
There is an ML-like type system that incorporates input-output examples. Two pieces: a \emph{refinement tree} and an enumerative search.\\
Two major operations: refine the goal type and the examples (push them down in the refinement tree) and guess a term of the right type that matches the examples (for one of the nodes of the refinement tree).\\
\end{enumerate}





%Leon (can bring it, it's deductive, so it's different than the others. It also targets functional programs. No, I have nothing to compare. The benchmark is too different.) \cite{LeonPaper}
%\begin{enumerate}
%\item What is the specification?
%Input-output relations (including examples), pre- and postconditions.
%\item What is the target language?
%Several recursion schemas (only terminating programs), components, pattern matching
%\item What can they do well and fast? How fast?
%The good thing is that they generate verified software. And it's interactive, the user can control the structure if he wants to.
%\item What is the difficulty? What can they not generate (or take a long time)? How much time?
%
%\item What do they do?
%Deductive synthesis, counterexample-guided.
%That's from the verification side: the point is to deliver \emph{verified} software that satisfies some specifications such as assertions, pre-conditions and post-conditions.
%\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
