\lstset{style=plain}

\chapter{A type-driven synthesis procedure} \label{ch:definitions}

In this chapter we will formally define our type-directed top-down synthesis procedure. We will start with an intuitive description thereof based on an example and move on to the formal definitions, starting with the target programming language and the search space. Finally, we will present some enhancements.

\section{The 'replicate' example}

Recall the example from Chapter~\ref{ch:introduction} where we wanted to synthesise the program corresponding to \lstinline?replicate.? As our synthesis procedure is type-driven and example-based, the user specifies a program by providing its type along with a few I/O-examples.\\
Let us specify \lstinline?replicate? as follows.
\begin{lstlisting}[style=plain]
replicate :: $\forall$X. Int -> X -> List X
replicate 3 1 = [1,1,1]
replicate 2 [] = [[],[]]
\end{lstlisting}

We also need a library of components from which we are going to compose our program. Let us assume that our library contains the standard list combinators \lstinline?map? and \lstinline?foldr?, \lstinline?enumTo?, that is the function that returns a list from $1$ up to its argument, and \lstinline?const?, that is the function that always returns its first argument. Moreover, the library also contains the list constructors \lstinline?cons? and \lstinline?[]? and the integer constructors \lstinline?succ? and \lstinline?0?. Even with so few library components, the search space is quite big.

The goal is to put together components from the library in a type-aware manner in order to get a list. More concretely, we fix \lstinline?X? to be a fixed input type variable, we fix \lstinline?n? to be an integer and \lstinline?x? to be a fixed input variable of type \lstinline?X?.
\begin{lstlisting}[style=plain]
replicate n x = ?p
?p :: List X
\end{lstlisting}
In the program above \lstinline!?p! is a \emph{hole}, that is a fresh variable starting with \lstinline!?! whose type is known. The goal is to find an instantiation for all holes and end up with a \emph{closed} program, that is a program without holes, that satisfies all input-output examples.

In this initial state, \lstinline!?p! is the only hole. We look for an instantiation of type \lstinline!List X!. To that end, we search for library components that return something of type \lstinline?List X?. We exclude \lstinline?enumTo?, because it only produces a list of integers, but all other possibilities are open. Namely, we could fold some list, map some function on a list or even use \lstinline?const? with a suitable first argument. But the first and easiest instantiation of type \lstinline?List X? is \lstinline?[]?. That is, our first program looks as follows.
\begin{lstlisting}[style=plain]
replicate n x = []
?p = [] :: List X
\end{lstlisting}
Since this program is closed, we can evaluate it on the input-output examples. However, it does not satisfy any of them. Therefore we must try the other four possible instantiations of \lstinline!?p! as well.

\begin{lstlisting}[style=plain]
replicate n x = cons ?x ?xs
?p = cons ?x ?xs :: List X
?x :: X
?xs :: List X
\end{lstlisting}

\begin{lstlisting}[style=plain]
replicate n x = foldr ?f ?init ?xs
?p = foldr ?f ?init ?xs :: List X
?f :: ?Y -> List X -> List X
?init :: List X
?xs :: List ?Y
\end{lstlisting}
Here \lstinline!?Y! is a fresh type variable that will be instantiated later. As of now we have no idea about the type of the first argument of \lstinline!?f!. The only thing we know is that it has to match the type of the elements of \lstinline!?xs!.

The other two possibilities to fill in \lstinline!?p! follow.

\begin{lstlisting}[style=plain]
replicate n x = const ?xs ?s
?p = const ?xs ?s :: List X
?xs :: List X
?s :: ?Y
\end{lstlisting}

\begin{lstlisting}[style=plain]
replicate n x = map ?f ?xs
?p = map ?f ?xs :: List X
?f :: ?Y -> X
?xs :: List ?Y
\end{lstlisting}

The synthesis procedure is based on \emph{best-first search}. That is, we maintain a frontier candidate solutions, in this case program with holes, and at each iteration we expand one of the holes of the most promising candidate program. At this point, the frontier of candidate solutions contains the four programs listed above.
The next step in the procedure, as already stated, is to expand one of the holes of the most promising candidate program.
Let us decide that the most promising program is the last one. In Section~\ref{Cost functions} we define cost functions on programs and define the most promising program to be the one with the smallest cost. For now we just choose the one that will lead us to the solution.

The most promising candidate program, \lstinline!replicate n x = map ?f ?xs!, has two holes to fill in: a function \lstinline!?f! that takes something and returns an \lstinline?X? and a list \lstinline!?xs! of something. We decide to expand the hole \lstinline!?f! first. Obviously, we cannot use \lstinline?map? or \lstinline?enumTo?, because they return lists, whereas \lstinline!?f! must return an \lstinline!X!. However, all other possibilities are open. We have to add following two programs to the frontier of candidate programs.

\begin{lstlisting}[style=plain]
replicate n x = map (foldr ?g ?init) ?xs
?p = map ?f ?xs :: List X
?f = foldr ?g ?init :: List ?Z -> X
?g :: ?Z -> X -> X
?init :: X
?xs :: List (List ?Z)
\end{lstlisting}
Note that we instantiated \lstinline!?Y! with \lstinline!List ?Z!, because \lstinline?foldr? takes a list as its last argument.

\begin{lstlisting}[style=plain]
replicate n x = map (const ?x) ?xs
?f = const ?x :: ?Y -> X
?x :: X
?xs :: List ?Y
\end{lstlisting}

After adding the new candidate programs to the frontier, we expand one of the holes of the most promising candidate program. Let us decide that the most promising program is the last one.
There are two holes to fill in: \lstinline!?x! of type \lstinline!X! and \lstinline!?xs! of type \lstinline!List ?Y!. For the first hole we have only one possibility: the second argument to \lstinline!replicate!, \lstinline!x!. Therefore we add following program to the frontier of candidate solutions.

\begin{lstlisting}[style=plain]
replicate n x = map (const x) ?xs
?p = map ?f ?xs :: List X
?f = const ?x :: ?Y -> X
?x = x :: X
?xs :: List ?Y
\end{lstlisting}

Let us directly decide that this is the most promising candidate program and let us expand its only hole, \lstinline!?xs!.
As in the beginning, we have to generate a list. However, since this time the type of the elements is not fixed, we cannot rule out  \lstinline?enumTo?.
Therefore we have a lot of possibilities to instantiate this hole, starting with \lstinline?[]? and ending with \lstinline!enumTo ?n! where \lstinline!?n! is a fresh hole of type \lstinline!Int!.

One of the candidate programs, \lstinline?replicate n x = map (const x) []?, is closed, therefore we evaluate it on the input-output examples. However, this program does not satisfy any of them.

For the sake of brevity and clarity, we omit all candidate solutions added to the frontier at this step except for the most promising program, that is
\begin{lstlisting}[style=plain]
replicate n x = map (const x) (enumTo ?n)
?p = map ?f ?xs :: List X
?f = const ?x :: ?Y -> X
?x = x :: X
?xs = enumTo ?n :: List Int
?n :: Int.
\end{lstlisting}
The only hole to expand is \lstinline!?n! and has type \lstinline!Int!. An integer hole can be instantiated by the constructor \lstinline?0?, the constructor \lstinline?succ? applied to another integer hole, the first argument of \lstinline?replicate?, or \lstinline?const? applied to an integer hole and some second argument.

The following two closed programs are among the candidate solutions added to the frontier at this step.
\begin{lstlisting}
replicate n x = map (const x) (enumTo 0)
\end{lstlisting}
\begin{lstlisting}
replicate n x = map (const x) (enumTo n)
\end{lstlisting}
Evaluation shows that only the second one satisfies the I/O-examples.

This example showed how we use best-first search to generate a program from components that satisfies the input-output examples. Even if type-aware expansion of holes helped to rule out ill-typed programs, the search space is quite big. Moreover, not all well-typed programs we generated are equally good. For example, the program \lstinline!replicate n x = const ?xs ?s! is \emph{superfluous} in that it is fully equivalent to the shorter program \lstinline!replicate n x = ?xs!. Superfluous programs can be ruled out based on the semantics of the components. In Section~\ref{Black list} we show one way to do it.

\subsection{Summary}

This example shows some important concepts that are defined formally in the next sections of this chapter.
\begin{description}
\item[Hole] unknown part of a program that can be instantiated with some other programs. Only its type is known.
\item[Closed program] a program without holes that can be evaluated on the input-output examples. The terms and the types of our calculus are formally defined in Section~\ref{Term and types}.
\item[Type-aware expansion of holes] we expand holes based on their type. In Section~\ref{Search space} we can find the rules according to which a program is expanded.
\item[Best first search] a frontier of programs with holes is maintained, one hole of the most promising is expanded in every iteration. The best first search algorithm is defined in Section~\ref{Exploration} and a notion of most promising program is presented in Section~\ref{Cost functions}.
\item[Superfluous program] a program that is equivalent to a shorter program. Section~\ref{Black list} shows one way to rule out superfluous programs.
\end{description}
 
\section{Calculus}

\TODO{fix the rest of it\\}
We represent our

In this section we will look at three different calculi.
\begin{enumerate}[1.]
\item System F
\item The internal language: an extension of System F with holes, input variables, library components, parametric types and recursive terms and types
\item The target language: a subset of the internal language, featuring only application of components, holes and input variables
\end{enumerate}

We provide the first calculus only for the sake of completeness, as the other two calculi build upon it. The notation and the exposition follow the excellent book on type systems of Benjamin Pierce \cite{pierce2002types}. We refer to the book for a thorough introduction to System F and to type systems in general.

The third calculus is the target language of our synthesiser. However, we still need the more powerful second calculus to define the library components and evaluate them on the input-output examples.


  \subsection{Terms and Types}\label{Term and types}
\paragraph{System F} System F, also known as the polymorphic lambda calculus, is a calculus that, additionally to term abstraction and term application, features two new kinds of terms: type abstraction \lstinline!$\Lambda$X. t! and type application \lstinline!t [T]!. This allows to express polymorphic functions. For example, the polymorphic identity function is defined as \lstinline!$\Lambda$X. $\lambda$x:X. x!.
Polymorphic functions, defined as type abstractions, have a special type: the \emph{universal} type \lstinline!$\forall$X. T!. For a more detailed introduction to System F we refer to \cite{pierce2002types}. The syntax is summarized below.

 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T]\\
(types): T ::= X | T \rightarrow T | \forall X.\; T\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
\end{plstx}


\paragraph{Internal language} We extend System F with holes $?x$, input variables $i$ as well as named library components $c$ and named types $C$ that can take parameters $C\; T_1\;\ldots\; T_K$. The number of type parameters supported by a named type is denoted as $K$ in its definition. The use of the names enables recursion in the definition of library components and types. Terms that do not contain holes are called \emph{closed}.
The syntax of our calculus is summarised below. Evaluation and typing rules for this calculus can be found in the respective subsections.

 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T] | c | {?x} | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\; T\;\ldots\; T\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}
Note that we have three additional contexts. $\Xi$ binds term holes to their types and type holes.
$\Phi$ is the library of input variables. It contains one concrete instantiation of the input variables. It binds a definition and a type signature to each input term variable and a definition to each input type variable.
$\Delta$ is the library of components. Each named term is bound to its definition and to its type signature and each named type is bound to ist definition and to the number of parameters it takes.


\paragraph{Target language} The target language of our synthesiser is a subset of the previous calculus. We are only interested in term and type application of library components, input variables and holes. Therefore, the syntax is restricted as follows.
 \begin{plstx}
(terms): t ::= t\;t | t\;[T] | c | ?x | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\; T\;\ldots\; T\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T : K\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}
Since this is a proper subset of the second calculus presented in this section, we do not need separate typing and evaluation rules.

\paragraph{Program} A program is defined as the 4-tuple $\{\Xi, \Phi, \Delta \vdash t :: T\}$, where $t$ is a term of the target language. A program is called \emph{closed} if $\Xi$ is empty and $t$ and $T$ do not contain holes.


  \subsection{Encodings}
Note that in the definition of types we do not see familiar types such as booleans, integers or lists. All these types can be encoded in System F using either the Church's or the Scott's encoding \cite{ScottNumerals}. We opted for the Scott's encoding because it is more efficient in our case.
Scott's booleans coincide with Church's booleans and are encoded as follows.
\begin{lstlisting}[style=plain, mathescape]
Bool  = $\forall$R. R $\rightarrow$ R $\rightarrow$ R
true  = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_1$
      : Bool
false = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_2$
      : Bool
if-then-else = $\Lambda$X. $\lambda$b:Bool. $\lambda$t:X. $\lambda$f:X. b [X] t f
             : $\forall$X. Bool $\rightarrow$ X $\rightarrow$ X $\rightarrow$ X
\end{lstlisting}

Scott's integers differ from Church's integers as they unwrap the constructor only once. Therefore they are more suitable for pattern matching.
\begin{lstlisting}[style=plain, mathescape]
Int = $\forall$R. R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
zero = $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. z
     : Int
succ = $\lambda$n:Int. $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. s n
     : Int $\rightarrow$ Int
case = $\Lambda$R. $\lambda$n:Int. $\lambda$a:R. $\lambda$f:Int $\rightarrow$ R. n [R] a f
     : $\forall$R. Int $\rightarrow$ R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
\end{lstlisting}

Analogously, Scott's lists are a recursive type and naturally support pattern matching.
\begin{lstlisting}[style=plain, mathescape]
List X = $\forall$R. R $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ R) $\rightarrow$ R
nil = $\Lambda$X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. n
    : $\forall$X. List X
con = $\Lambda$X. $\lambda$x:X. $\lambda$xs:List X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. c x xs
    : $\forall$X. X $\rightarrow$ List X $\rightarrow$ List X
case = $\Lambda$X. $\Lambda$Y. $\lambda$l:List X. $\lambda$n:Y. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ Y. l [Y] n c
     : $\forall$X. $\forall$Y. List X $\rightarrow$ Y $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ Y) $\rightarrow$ Y
\end{lstlisting} 
 
  \subsection{Evaluation semantics}
In this section we present the evaluation semantics of our internal language, that is the second calculus introduced in Section~\ref{Term and types}. The evaluation semantics is a standard eager evaluation and we refer to the excellent book of Benjamin Pierce about type systems \cite{pierce2002types} for an introduction to the evaluation semantics of System F and evaluation rules in general.

The evaluation judgement $\Phi, \Delta \vdash t \longrightarrow t'$ means that the term $t$ evaluates in one step to the term $t'$ under the free variable bindings library $\Phi$, that contains concrete instantiations for the input variables, and the component library $\Delta$, that contains the definitions of the library components. Before listing the evaluation rules, let us define \emph{value} $v$ to be a term to which no evaluation rule apply.

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{E-Lib}
	\UnaryInfC{$\Phi, \Delta \vdash c \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{E-Inp}
	\UnaryInfC{$\Phi, \Delta \vdash i \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_1 \longrightarrow t_1'$}
	\RightLabel{E-App1}
	\UnaryInfC{$\Phi, \Delta \vdash t_1\; t_2 \longrightarrow t_1'\; t_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_2 \longrightarrow t_2'$}
	\RightLabel{E-App2}
	\UnaryInfC{$\Phi, \Delta \vdash v_1\; t_2 \longrightarrow v_1\; t_2'$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{E-AppAbs}
	\UnaryInfC{$\Phi, \Delta \vdash (\lambda x:T_{11}.\; t_{12})\; v_2 \longrightarrow [x \mapsto v_2]t_{12}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{\textsc{E-AppAbs}}
	\UnaryInfC{$\Phi, \Delta \vdash (\Lambda X.\; t_2)\; [T_2] \longrightarrow [X \mapsto T_2]t_2$}
\end{prooftree}  
  
Rules E-Lib and E-Inp load the definitions of library components or input variables from the respective library. E-App1 and E-App2 evaluate the left hand side, respectively the right hand side, of an application. E-AppAbs and \textsc{E-AppAbs} get rid of an abstraction and substitute the argument into the body.\\
Note that E-App2 applies only if the left hand side of the application cannot be evaluated further and that E-AppAbs applies only when the argument of the lambda abstraction is a value, determining the order of evaluation.

\subsection{Type checking}

In this sections we will present the typing rules of our internal language, that is the second calculus presented in Section~\ref{Term and types}. The typing judgement $\Gamma, \Xi, \Phi, \Delta \vdash t : T$ means the term $t$ has type $T$ in the contexts $\Gamma$ and $\Xi$, binding respectively variables and holes, and $\Phi$ and $\Delta$, containing signatures and definitions of respectively input variables and library components. The typing judgement is similar to the typing judgement of System F presented in the book about type systems of Benjamin Pierce \cite{pierce2002types}. As usual, we refer to the book for more details.
  
\begin{prooftree}
\AxiomC{$x : T \in \Gamma$}
	\RightLabel{T-Var}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash x : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{${?x} : T \in \Xi$}
	\RightLabel{T-Hol}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash {?x} : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{T-Inp}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash i : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{T-Lib}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash c : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{x : T_1\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{T-Abs}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \lambda x : T_1.\; t_2 : T_1 \rightarrow T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : T_1 \rightarrow T_2$}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_2 : T_1$}
	\RightLabel{T-App}
	\BinaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;t_2 : T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{X\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{\textsc{T-Abs}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \Lambda X.\; t_2 : \forall X.\; T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : \forall X.\; T_{12}$}
	\RightLabel{\textsc{T-App}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;[T_2] : [X \mapsto T_2]T_{12}$}
\end{prooftree}

The rules T-Var, T-Hol, T-Inp and T-Lib load the signature of variables, holes, input variables or library components from the respective context.
T-Abs types a lambda abstraction as an arrow type from the type of its variable to the type of its body. \textsc{T-Abs} gives a type abstraction a universal type in accordance to the type of its body.
An application typechecks only if the left hand side has an arrow type and the type of the argument is equal to the type of the argument of the left hand side. Analogously, a type application typechecks only if the left hand side has a universal type.

\subsection{Type unification}

In order to identify the library components that can be used to instantiate a hole of a given type, we need type unification. Consider, for example, a hole of type \lstinline?List Int -> Int?. We want to instantiate this hole not only with components that have precisely this type, like \lstinline?sum? and \lstinline?prod?, but also components with a more general type that can be matched to the desired type through type application, like \lstinline?head :: $\forall$X. List X -> X? and \lstinline?length :: $\forall$X. List X -> Int?.

Alas, unification on the type system of System F is undecidable \cite{Huet1975}.
Therefore we chose to restrict our type system to universally quantified types, that is types of the form \lstinline?$\forall X_1$. $\ldots$ $\forall X_n$. T($X_1, \ldots, X_n$)? where \lstinline?T($X_1, \ldots, X_n$)? is quantifier-free.
This allows us to completely ignore universal types during unification. Instead, we can represent \lstinline?$\forall X_1$. $\ldots$ $\forall X_n$. T($X_1, \ldots, X_n$)? as \lstinline!T(?$X_1$, $\ldots$, ?$X_n$)!, that is leave out all quantifiers and replace the bound variables with fresh type holes.

Our unification algorithm (summarised as Algorithm~\ref{alg:type unification} below) is based on the unification algorithm for typed lambda calculus from \cite{pierce2002types} and slightly modified to fit our needs.

A set of constraints is a set of types that should be equal under a substitution. The unification algorithm is supposed to output a substitution $\sigma$ so that $\sigma(S) = \sigma(T)$ for every constraint $S = T$ in $\C$. A substitution maps holes to types.

A type hole unifies with anything. An arrow type \lstinline?$T_1$ -> $T_2$? unifies either with a type hole or with another arrow type \lstinline?$T_3$ -> $T_4$? if \lstinline?$T_1$? unifies with \lstinline?$T_3$? and \lstinline?$T_2$? with \lstinline?$T_4$?. A named type applied to all of its parameters \lstinline?C $T_{11}$ $\ldots$ $T_{1k}$? unifies either with a type hole or with the same named type applied to the same number of parameters \lstinline?C $T_{21}$ $\ldots$ $T_{2k}$? if the respective parameters \lstinline?$T_{1j}$? and \lstinline?$T_{2j}$? unify for all $j = 1, \ldots, k$. Universal  types unify only with type holes and should not appear in the set of constraints.

\begin{algorithm}
\caption{Type unification\label{alg:type unification}}
\KwIn{Set of constraints $\C = \{T_{11} = T_{12}, T_{21} = T_{22}, \ldots\}$}
\KwOut{Substitution $\sigma$ so that $\sigma(T_{i1}) = \sigma(T_{i2})$ for every constraint $T_{i1} = T_{i2}$ in $\C$}

\SetKwProg{Fn}{Function}{ is}{end}
\Fn{unify($\C$)}{
	\DontPrintSemicolon
	\lIf{$\C = \emptyset$}{
		[]
	}\Else{let $\{T_1 = T_2\} \cup \C' = \C$ in\\
		\uIf{$T_1 = T_2$}{
			\textit{unify}$(\C')$
		}\uElseIf{$T_1 = {?X}$ and ${?X}$ does not occur in $T_2$}{
			\textit{unify}$([?X \mapsto T_2]\C') \circ [?X \mapsto T_2]$
		}\uElseIf{$T_2 = {?X}$ and ${?X}$ does not occur in $T_1$}{
			\textit{unify}$([?X \mapsto T_1]\C') \circ [?X \mapsto T_1]$
		}\uElseIf{$T_1 = T_{11} \rightarrow T_{12}$ and $T_2 = T_{21} \rightarrow T_{22}$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}\})$
		}\uElseIf{$T_1 = C\;T_{11}\; T_{12}\; \ldots\; T_{1k}$ and $T_2 = C\; T_{21}\; T_{22}\; \ldots,\; T_{2k}$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}, \ldots, T_{1k} = T_{2k}\})$
		}\Else{
			\textit{fail}
		}
	}
}
\end{algorithm} 

\section{Search}
After defining the target language, the evaluation semantics, the type checking and the type unification, we are ready to formally define the problem.

\paragraph{Problem definition} Given a library $\Delta$, a goal type $T$ and a list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, find a closed term $t$ in the target language such that
\begin{enumerate}[(i)]
\item the abstraction of $t$ over all of its type and term input variables has the goal type under an empty variable binding context and an empty hole binding context, that is $\emptyset, \emptyset, \Phi_1, \Delta \vdash t' : T$ where $t'$ is \[\Lambda X_1.\; \ldots\; \Lambda X_j.\; \lambda x_1.\; \ldots\; \lambda x_k.\; [I_1 \mapsto X_1, \ldots, I_j \mapsto X_j, i_1 \mapsto x_1, \ldots, x_k \mapsto x_k]t.\]
\item $t$ satisfies all input-output examples, that is $\Phi_n, \Delta \vdash t \longrightarrow^* t'$ and $\Phi_n, \Delta \vdash o_n \longrightarrow^* t'$ for all $n = 1, \ldots, N$.
\end{enumerate}

In Section~\ref{Search space} we define the search space and in Section~\ref{Exploration} we describe the main enumeration algorithm, a standard best-first search.

\subsection{Search space}\label{Search space}
We see the search space as a graph, where the vertices correspond to \emph{programs}. Recall that a program is the 4-tuple $\{\Xi, \Phi, \Delta \vdash t :: T'\}$, where $t$ is a term of the target language. The type $T'$ can be transformed into the goal type $T$ abstracting over all type and term input variables. That is, if $\Phi$ contains the type input variables $I_1, \ldots, I_j$ and the signatures of the term input variables $i_1 : T_1, \ldots, i_k : T_k$, then the goal type $T$ should be equal to
\[\forall X_1.\; \ldots \forall X_j.\; [I_1 \mapsto X_1, \ldots, I_j \mapsto X_j] (T_1 \rightarrow \ldots \rightarrow T_k \rightarrow T').\]

There is a directed edge between two programs $\{\Xi_1, \Phi, \Delta \vdash t_1 :: T'\}$ and $\{\Xi_2, \Phi, \Delta \vdash t_2 :: T'\}$ if and only if the judgement \emph{derive} (defined below) $\Xi, \Phi, \Delta \vdash t_1 :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_2 :: T_2$ holds between the two.

To express the rules of the derive judgement in a more compact form, we introduce \emph{evaluation contexts}. An evaluation context is an expression with exactly one syntactic hole $[]$ in which we can plug in any term. For example, if we have the context $\mathcal{E}$ we can place the term $t$ into its hole and denote this new term by $\mathcal{E}[t]$.

The derive judgement can be summarised by the following four rules.\\
D-VarLib replaces a hole $?x$ with a type application of a library component $c$ to the right types, if the type of $c$ unifies with the type of $?x$. D-VarInp replaces a hole $?x$ with an input variable $i$ from the context $\Phi$, if it has the right type. D-VarApp turns a hole into a term application of two fresh holes. The rule D-App chooses a hole in the program and expands it according to one of the three rules above.

\TODO{do we need following paragraph? It adds nothing to the rule.\\}
The rule D-VarLib might require a more detailed explanation.
Let $\mathcal{A}$ be the class of quantifier-free types. Let \lstinline?c : $\forall X_1$. $\ldots$ $\forall X_n$. $T_c$($X_1, \ldots, X_n$)? $\in \Delta$ where \lstinline?$T_c$($X_1, \ldots, X_n$)? belongs to class $\mathcal{A}$. Let \lstinline!?$X_1$, $\ldots$, ?$X_n$! be fresh type holes not present in $\Xi$. Let $\sigma$ be the unifier of $T$ with \lstinline!$T_c$(?$X_1$, $\ldots$, ?$X_n$)!. Then we can replace the hole \lstinline!?x! with \lstinline!c [$\sigma$(?$X_1$)] $\ldots$ [$\sigma$(?$X_n$)]!.

The notation $\sigma(\Xi)$ denotes the application of the substitution $\sigma$ to all types appearing in $\Xi$.

\begin{prooftree}
\AxiomC{$c : \forall X_1.\; \ldots \forall X_n.\; T_c(X_1, \ldots, X_n) \in \Delta$}
\noLine
\UnaryInfC{$?X_1, \ldots, ?X_n$ are fresh type holes}
\noLine
\UnaryInfC{$\sigma$ unifies $T$ with $T_c(?X_1, \ldots, ?X_n)$}
\noLine
\UnaryInfC{$\Xi' = \Xi \cup \{{?X_1}, \ldots, {?X_n}\} \setminus \{{?x} : T\}$}
	\RightLabel{D-VarLib}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi'), \Phi, \Delta \vdash c\; [\sigma(?X_1)]\; \ldots\; [\sigma(?X_n)] :: \sigma(T) $
	}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i : T_i \in \Phi$}
\AxiomC{$\sigma$ unifies $T$ with $T_i$}
	\RightLabel{D-VarInp}
	\BinaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi \setminus \{{?x} : T\}), \Phi, \Delta \vdash i :: \sigma(T) $
	}
\end{prooftree}


\begin{prooftree}
\AxiomC{$?X$ is a fresh type variable}
\noLine
\UnaryInfC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{D-VarApp}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_1' :: T_1'$}
	\RightLabel{D-App}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}

Note that all derived programs are well-types and, since the types of all derived programs unify with the types of their ancestors, have the right type.

\subsection{Best-first search}\label{Exploration}
Our enumeration procedure traverses the search graph defined in the previous section using standard best-first search. The algorithm maintains a frontier of candidate programs and expands one hole of the most promising program in each iteration. Closed programs are evaluated on the input-output examples. The search terminates when the first program that satisfies all input-output examples is found.

There are two points where Algorithm~\ref{alg:best-first search} can be tweaked.
\begin{enumerate}
\item Which candidate program is the most promising?
\item Which hole of the most promising program should be expanded?
\end{enumerate}
The first question is addressed by the implementation of the \lstinline?compare? function over programs. Section~\ref{Cost functions} discusses different approaches to define it.

The second question is addressed by the implementation of the \lstinline?successor? function. In particular, the implementation of the D-App rule. There are two easy ways to handle this problem. The first way is to always expand the leftmost hole, the second way is to always expand the oldest hole.

\begin{algorithm}
\caption{Best first search\label{alg:best-first search}}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$}
\KwOut{closed program $\{\Xi, \Phi_1, \Delta \vdash t :: T\}$ that satisfies all I/O-examples}

queue $\gets$ PriorityQueue.empty {\color{blue}compare}\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	successors $\gets$ {\color{blue}successor} (PriorityQueue.top queue)\\
	queue $\gets$ PriorityQueue.pop queue\\
	\For{all s in successors}{
		queue $\gets$ PrioriryQueue.push queue s\\
	}
}
\Return{PriorityQueue.top queue}
\end{algorithm}

\section{Cost functions}\label{Cost functions}
\TODO{General TODO: decide how do you want to call your cost functions. Now they are everywhere called nof-nodes, nof-nodes-simple-type and no-same-component. Maybe you want some simpler and shorter name.\\}
The compare function in the best-first search algorithm can be defined as \lstinline?cost $p_1$ - cost $p_2$?. There are different possibilities to define this cost function. We will present four alternatives. All of them are based on the idea that shorter and simpler programs generalise better to unseen examples, along the lines of the Occam's razor principle \cite{computationalLearningTheory}. The first three alternatives were evaluated on benchmarks and their effect on performance is discussed in Section~\ref{Eval. Cost functions}.

  \paragraph{nof-nodes}
The first cost function is based only on the number of nodes of the term. It prioritises shorter programs and prefers input variables over library components over holes.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes}(c) = 1$
$\textit{nof-nodes}({?x}) = 2$
$\textit{nof-nodes}(i) = 0$
$\textit{nof-nodes}(t_1\; t_2) = 1 + \textit{nof-nodes}(t_1) + \textit{nof-nodes}(t_2)$
$\textit{nof-nodes}(t\; [T]) = 1 + \textit{nof-nodes}(t)$
\end{lstlisting}
%
  \paragraph{nof-nodes-simple-type}
The second cost function also adds a factor based on the size of the types appearing in the term. It penalises thus terms with type application depending on the applied types. In particular, arrow types appearing in type applications are heavily penalised.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes-type}(X) = 1$
$\textit{nof-nodes-type}({?X}) = 0$
$\textit{nof-nodes-type}(I) = 0$
$\textit{nof-nodes-type}(C\; T_1\; \ldots\; T_k) = 0$
$\textit{nof-nodes-type}(T_1 \rightarrow T_2) = 3 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$

$\textit{nof-nodes-term}(c) = 1$
$\textit{nof-nodes-term}({?x}) = 2$
$\textit{nof-nodes-term}(i) = 0$
$\textit{nof-nodes-term}(t_1\; t_2) = 1 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$
$\textit{nof-nodes-term}(t\; [T]) = 1 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$

$\textit{nof-nodes-and-types}(t) = \textit{nof-nodes-term}(t)$
\end{lstlisting}

  \paragraph{no-same-component}
In the third cost function we additionally penalize terms that use the same component more than once.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes-type}({?X}) = 3$
$\textit{nof-nodes-type}(I) = 0$
$\textit{nof-nodes-type}(C\; T_1\; \ldots\; T_k)$= $4 + \textit{nof-nodes-type}(T_1) + \ldots + \textit{nof-nodes-type}(T_k)$
$\textit{nof-nodes-type}(T_1 \rightarrow T_2) = 5 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$

$\textit{nof-nodes-term}(c) = 3$
$\textit{nof-nodes-term}({?x}) = 2$
$\textit{nof-nodes-term}(i) = 0$
$\textit{nof-nodes-term}(t_1\; t_2) = 6 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$
$\textit{nof-nodes-term}(t\; [T]) = 5 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$

$\textit{count}(t) = \displaystyle \sum_{c_i \text{ appears in } t} \text{(occurrences of } c_1 \text{ in } t) - 1$

$\textit{no-same-component}(t) = \textit{nof-nodes-term}(t) + 3\; \textit{count}(t)$
\end{lstlisting}

  \paragraph{string-length}
The simplest and most imprecise method to take both the number of nodes and the complexity of the types appearing in the term into account is to define the cost of a term as the length of the string representing that term. This method also allows a simple way to weight differently the various library components by choosing a shorter or longer name. However, we decided not to use this cost function for evaluation.

\section{Black list}\label{Black list}
Recall the 'replicate' example, where we saw the superfluous program \lstinline!const [?X] ?$x_1$ ?$x_2$!. The best-first enumeration explores many superfluous branches like \lstinline!foldr [?X] [List ?X] (cons [?X]) (nil [?X]) ?xs! or \lstinline!add zero ?n!. Such programs can be ruled out only based on the semantics of the library components. A simple way to prune those superfluous branches is to compile a list of undesired patterns and check each generated program against this list. This is what we call \emph{black list pruning}.

A black list is a list of terms of the target language. Programs that contain a subterm that matches a term from the black list are removed from the candidate programs and their successors are ignored.

The relation \textit{matches} over terms is inductively defined as follows.
\begin{algorithm*}
\textit{matches}$({?x},t)$\\
\textit{matches}$(i,t)$\\
\textit{matches}$(c,c)$\\
\textit{matches}$(t_1\; t_2,t_3\; t_4)$ if \textit{matches}$(t_1,t_3)$ and \textit{matches}$(t_2,t_4)$\\
\textit{matches}$(t_1\; [T_1],t_2\; [T_1])$ if \textit{matches}$(t_1,t_2)$\\
\end{algorithm*}
As you can see, holes and input variables in the black list match every subterm, a library component matches only itself, a term application matches a term application whose respective left- and right hand sides match and a type application matches a type application if the left hand sides match. Note that the types in a type application are completely ignored.

Pruning based on black lists can be easily integrated in Algorithm~\ref{alg:best-first search}. The result is shown in Algorithm~\ref{alg:blacklist pruning}, where the differences to the original best-first search are highlighted in blue.

\begin{algorithm}
\caption{Best first search with black list\label{alg:blacklist pruning}}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, black list $[b_1, \ldots , b_M]$}

queue $\gets$ PriorityQueue.empty compare\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	\uIf{{\color{blue}not ((PriorityQueue.top queue) contains subterm from black list)}}{
		successors $\gets$ successor (PriorityQueue.top queue)\\
		queue $\gets$ PriorityQueue.pop queue\\
		\For{all s in successors}{
			queue $\gets$ PrioriryQueue.push queue s\\
		}
	}\Else{
		queue $\gets$ PriorityQueue.pop queue\\
	}
}
\KwOut{PriorityQueue.top queue}
\end{algorithm}

In Section~\ref{Black list generation} we discuss how to synthesise such a black list automatically.

\section{Templates}\label{Templates}
In this section we present a slightly different way to explore the search space. The idea is to fix all higher-order components first, producing a \emph{template} for a program, and then fill in the remaining holes with input variables and first-order components. Since programs usually contain only a few higher-order components, the enumeration of templates takes less time than the enumeration of programs of comparable size. Moreover, templates encode well-known patterns of computation and impose meaningful constraints on the remaining holes. Therefore, it should be easy to find the desired program starting from the right template. This allows us to quickly abandon templates if no program satisfying the input-output examples is found within a short timeout.

Let us formally define a template and describe the procedure.

The library $\Delta$ is split into two contexts: $\Delta_h$, containing all higher-order components, and $\Delta_f$, containing the first-order ones. We also need to introduce a new kind of term: the \emph{delayed hole} $\underline{?x}$. This is a hole, whose instantiation is delayed to the first-order search. The context $\Xi$ binds, additionally to normal holes, delayed holes as well.
A \emph{template} is a term in the target language that may contain delayed holes but does not contain input variables. A template is called \emph{closed} if it does not contain holes (it may, however, contain delayed holes).

The synthesis procedure iterates between two phases: enumeration of templates and, as soon as a closed template is found, enumeration of programs as in Algorithm~\ref{alg:best-first search} using $\Delta_f$ for a limited period of time or until a program satisfying all input-output examples is found.

We additionally restrict the space by requiring a template to have no more than $M$ higher-order components and no more than $P$ delayed holes. Templates are enumerated according to the rules listed below. Those are very similar to the ones defined in Section~\ref{Search space}, except that we cannot instantiate a hole with an input variable but we can delay a hole. All the rules are modified to take into account the restriction on the number of components and the number of closed holes. In order to do this, we need to pass along $m$, the number of higher-order components in the term whose subterms we are traversing.

Analogously to D-VarLib, the rule G-VarLib instantiates a hole with a type application of a higher-order library components to the right types, if the type of the component unifies with the type of the hole. The rule G-VarDelay delays the instantiation of a hole to the first-order search. G-VarApp replaces a hole with a term application of two fresh holes. G-App expands one of the holes of the template according to one of the three rules listed above. Note that there are no rules to expand a delayed hole.

\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m < M$}
\noLine
\UnaryInfC{$c : \forall X_1.\; \ldots \forall X_n.\; T_c(X_1, \ldots, X_n) \in \Delta_h$}
\noLine
\UnaryInfC{$?X_1, \ldots, ?X_n$ are fresh type holes}
\noLine
\UnaryInfC{$\sigma$ unifies $T$ with $T_c(?X_1, \ldots, ?X_n)$}
\noLine
\UnaryInfC{$\Xi' = \Xi \cup \{{?X_1}, \ldots, {?X_n}\} \setminus \{{?x} : T\}$}
	\RightLabel{G-VarLib}
	\UnaryInfC{$\Xi, \Phi, \Delta_h \vdash {?x} :: T \Mapsto \sigma(\Xi'), \Phi, \Delta_h \vdash c\; [\sigma(?X_1)]\; \ldots\; [\sigma(?X_n)] :: \sigma(T) $
	}
\end{prooftree}

\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m \leq M$}
	\RightLabel{G-VarDelay}
	\UnaryInfC{$\Xi, \Phi, \Delta_h, m \vdash {?x} :: T \Mapsto \Xi \setminus \{{?x}:T\} \cup \{\underline{?x}:T\}, \Phi, \Delta_h, m \vdash {\underline{?x}} :: T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$|\Xi| < P$ and $m \leq M$}
\noLine
\UnaryInfC{$?X$ is a fresh type variable}
\noLine
\UnaryInfC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{G-VarApp}
	\UnaryInfC{$\Xi, \Phi, \Delta_h \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta_h \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_1' :: T_1'$}
	\RightLabel{G-App}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
