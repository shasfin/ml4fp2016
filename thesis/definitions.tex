\lstset{style=plain}

\chapter{A type-driven synthesis procedure} \label{ch:definitions}

In this chapter we will formally define our type-directed top-down synthesis procedure. We will start with an intuitive description thereof based on an example and move on to the formal definitions, starting with the target programming language and the search space. Finally, we will present some enhancements.

\input{example}
 
\section{Calculus}

This section formally defines the language of our synthesiser.

In this section we formally define the internal language of our synthesiser.
\TODO{TODO introducting words to the whole section.\\}
We represent our

We provide the first calculus only for the sake of completeness, as the other two calculi build upon it. The notation and the exposition follow the excellent book on type systems of Benjamin Pierce \cite{pierce2002types}. We refer to the book for a thorough introduction to System F and to type systems in general.

The third calculus is the target language of our synthesiser. However, we still need the more powerful second calculus to define the library components and evaluate them on the input-output examples.

To summarise, in this section we will look at the following three calculi.
\begin{enumerate}[1.]
\item System F
\item The internal language: an extension of System F with holes, input variables, library components, parametric types and recursive terms and types
\item The target language: a subset of the internal language, featuring only application of components, holes and input variables
\end{enumerate}


  \subsection{Terms and Types}\label{Term and types}
\paragraph{System F} System F, also known as the polymorphic lambda calculus, is a calculus that, additionally to term abstraction and term application, features two new kinds of terms: type abstraction \lstinline!$\Lambda$X. t! and type application \lstinline!t [T]!. This allows to express polymorphic functions. For example, the polymorphic identity function is defined as \lstinline!$\Lambda$X. $\lambda$x:X. x!.
Polymorphic functions, defined as type abstractions, have a special type: the \emph{universal} type \lstinline!$\forall$X. T!. For a more detailed introduction to System F we refer to \cite{pierce2002types}. The syntax is summarized below.

 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T]\\
(types): T ::= X | T \rightarrow T | \forall X.\; T\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
\end{plstx}


\paragraph{Internal language} We extend System F with holes $?x$, input variables $i$ as well as named library components $c$ and named types $C$ that can take parameters $C\; T_1\;\ldots\; T_K$. The number of type parameters supported by a named type is denoted as $K$ in its definition. The use of the names enables recursion in the definition of library components and types. Terms that do not contain holes are called \emph{closed}.
The syntax of our calculus is summarised below. Evaluation and typing rules for this calculus can be found in the respective subsections.

 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T] | c | {?x} | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\; T\;\ldots\; T\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}
Note that we have three additional contexts. The first one, $\Xi$, binds term holes to their types and type holes.
The second one, $\Phi$, is the library of input variables. It contains one concrete instantiation of the input variables. It binds a definition and a type signature to each input term variable and a definition to each input type variable.
The third one, $\Delta$, is the library of components. Each named term is bound to its definition and to its type signature and each named type is bound to ist definition and to the number of parameters it takes.


\paragraph{Target language} The target language of our synthesiser is a subset of the internal language. We are only interested in term and type application of library components, input variables and holes. Therefore, the syntax is restricted as follows.
 \begin{plstx}
(terms): t ::= t\;t | t\;[T] | c | ?x | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\; T\;\ldots\; T\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T : K\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}
Since this is a proper subset of the second calculus presented in this section, we do not need separate typing and evaluation rules.

\paragraph{Program} A program is defined as the 4-tuple $\{\Xi, \Phi, \Delta \vdash t :: T\}$, where $t$ is a term of the target language. A program is called \emph{closed} if $\Xi$ is empty and $t$ and $T$ do not contain holes.


  \subsection{Encodings}
In the definition of types familiar types such as booleans, integers or lists do not appear. All these types can be encoded in System F using either Church's or Scott's encoding \cite{ScottNumerals}. We opt for Scott's encoding because it is more efficient in our case.
Scott's booleans coincide with Church's booleans and are encoded as follows.
\begin{lstlisting}[style=plain, mathescape]
Bool  = $\forall$R. R $\rightarrow$ R $\rightarrow$ R
true  = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_1$
      : Bool
false = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_2$
      : Bool
if-then-else = $\Lambda$X. $\lambda$b:Bool. $\lambda$t:X. $\lambda$f:X. b [X] t f
             : $\forall$X. Bool $\rightarrow$ X $\rightarrow$ X $\rightarrow$ X
\end{lstlisting}

Scott's integers differ from Church's integers as they unwrap the constructor only once. Therefore they are more suitable for pattern matching.
\begin{lstlisting}[style=plain, mathescape]
Int = $\forall$R. R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
zero = $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. z
     : Int
succ = $\lambda$n:Int. $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. s n
     : Int $\rightarrow$ Int
case = $\Lambda$R. $\lambda$n:Int. $\lambda$a:R. $\lambda$f:Int $\rightarrow$ R. n [R] a f
     : $\forall$R. Int $\rightarrow$ R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
\end{lstlisting}

Analogously, Scott's lists are a recursive type and naturally support pattern matching.
\begin{lstlisting}[style=plain, mathescape]
List X = $\forall$R. R $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ R) $\rightarrow$ R
nil = $\Lambda$X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. n
    : $\forall$X. List X
con = $\Lambda$X. $\lambda$x:X. $\lambda$xs:List X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. c x xs
    : $\forall$X. X $\rightarrow$ List X $\rightarrow$ List X
case = $\Lambda$X. $\Lambda$Y. $\lambda$l:List X. $\lambda$n:Y. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ Y. l [Y] n c
     : $\forall$X. $\forall$Y. List X $\rightarrow$ Y $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ Y) $\rightarrow$ Y
\end{lstlisting} 
 
  \subsection{Evaluation semantics}
In this section we present the evaluation semantics of our internal language, that is the second calculus introduced in Section~\ref{Term and types}. The evaluation semantics is a standard eager evaluation and we refer to the excellent book of Benjamin Pierce about type systems \cite{pierce2002types} for an introduction to the evaluation semantics of System F and evaluation rules in general.

The evaluation judgement $\Phi, \Delta \vdash t \longrightarrow t'$ means that the term $t$ evaluates in one step to the term $t'$ under the free variable bindings library $\Phi$, that contains concrete instantiations for the input variables, and the component library $\Delta$, that contains the definitions of the library components. Before listing the evaluation rules, let us define \emph{value} $v$ to be a term to which no evaluation rule apply.

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{E-Lib}
	\UnaryInfC{$\Phi, \Delta \vdash c \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{E-Inp}
	\UnaryInfC{$\Phi, \Delta \vdash i \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_1 \longrightarrow t_1'$}
	\RightLabel{E-App1}
	\UnaryInfC{$\Phi, \Delta \vdash t_1\; t_2 \longrightarrow t_1'\; t_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_2 \longrightarrow t_2'$}
	\RightLabel{E-App2}
	\UnaryInfC{$\Phi, \Delta \vdash v_1\; t_2 \longrightarrow v_1\; t_2'$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{E-AppAbs}
	\UnaryInfC{$\Phi, \Delta \vdash (\lambda x:T_{11}.\; t_{12})\; v_2 \longrightarrow [x \mapsto v_2]t_{12}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{\textsc{E-AppAbs}}
	\UnaryInfC{$\Phi, \Delta \vdash (\Lambda X.\; t_2)\; [T_2] \longrightarrow [X \mapsto T_2]t_2$}
\end{prooftree}  
  
Rules E-Lib and E-Inp load the definitions of library components or input variables from the respective library. E-App1 and E-App2 evaluate the left hand side, respectively the right hand side, of an application. E-AppAbs and \textsc{E-AppAbs} get rid of an abstraction and substitute the argument into the body.\\
Note that E-App2 applies only if the left hand side of the application cannot be evaluated further and that E-AppAbs applies only when the argument of the lambda abstraction is a value, determining the order of evaluation.

\subsection{Type checking}

In this sections we will present the typing rules of our internal language, that is the second calculus presented in Section~\ref{Term and types}. The typing judgement $\Gamma, \Xi, \Phi, \Delta \vdash t : T$ means the term $t$ has type $T$ in the contexts $\Gamma$ and $\Xi$, binding respectively variables and holes, and $\Phi$ and $\Delta$, containing signatures and definitions of respectively input variables and library components. The typing judgement is similar to the typing judgement of System F presented in the book about type systems of Benjamin Pierce \cite{pierce2002types}. As usual, we refer to the book for more details.
  
\begin{prooftree}
\AxiomC{$x : T \in \Gamma$}
	\RightLabel{T-Var}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash x : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{${?x} : T \in \Xi$}
	\RightLabel{T-Hol}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash {?x} : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{T-Inp}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash i : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{T-Lib}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash c : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{x : T_1\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{T-Abs}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \lambda x : T_1.\; t_2 : T_1 \rightarrow T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : T_1 \rightarrow T_2$}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_2 : T_1$}
	\RightLabel{T-App}
	\BinaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;t_2 : T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{X\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{\textsc{T-Abs}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \Lambda X.\; t_2 : \forall X.\; T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : \forall X.\; T_{12}$}
	\RightLabel{\textsc{T-App}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;[T_2] : [X \mapsto T_2]T_{12}$}
\end{prooftree}

The rules T-Var, T-Hol, T-Inp and T-Lib load the signature of variables, holes, input variables and, respectively, library components from the respective contexts.
T-Abs types a lambda abstraction as an arrow type from the type of its variable to the type of its body. \textsc{T-Abs} gives a type abstraction a universal type in accordance to the type of its body.
An application typechecks only if the left hand side has an arrow type and the type of the argument is equal to the type of the argument of the left hand side. Analogously, a type application typechecks only if the left hand side has a universal type.

\subsection{Type unification}

In order to identify the library components that can be used to instantiate a hole of a given type, we need type unification. Consider, for example, a hole of type \lstinline?List Int -> Int?. We want to instantiate this hole not only with components that have precisely this type, like \lstinline?sum? and \lstinline?prod?, but also components with a more general type that can be matched to the desired type through type application, like \lstinline?head :: $\forall$X. List X -> X? and \lstinline?length :: $\forall$X. List X -> Int?.

However, unification on the type system of System F is undecidable \cite{Huet1975}.
Therefore we chose to restrict our type system to quantifier-free forms.
This allows us to completely ignore universal types during unification. However, we still want to handle universally quantified library components, that is components whose type has the form \lstinline?$\forall X_1$. $\ldots$ $\forall X_n$. T($X_1, \ldots, X_n$)? where \lstinline?T($X_1, \ldots, X_n$)? is quantifier-free. To this end, we represent type of the form \lstinline?$\forall X_1$. $\ldots$ $\forall X_n$. T($X_1, \ldots, X_n$)? as \lstinline!T(?$X_1$, $\ldots$, ?$X_n$)!, that is we leave out all quantifiers and replace the bound variables with fresh type holes.

Our unification algorithm (summarised as Algorithm~\ref{alg:type unification} below) is based on the unification algorithm for typed lambda calculus from \cite{pierce2002types} and slightly modified to fit our needs.

A set of constraints is a set of types that should be equal under a substitution. The unification algorithm is supposed to output a substitution $\sigma$ so that $\sigma(S) = \sigma(T)$ for every constraint $S = T$ in $\C$. A substitution maps holes to types.

A type hole unifies with anything. An arrow type \lstinline?$T_1$ -> $T_2$? unifies either with a type hole or with another arrow type \lstinline?$T_3$ -> $T_4$? if \lstinline?$T_1$? unifies with \lstinline?$T_3$? and \lstinline?$T_2$? with \lstinline?$T_4$?. A named type applied to all of its parameters \lstinline?C $T_{11}$ $\ldots$ $T_{1k}$? unifies either with a type hole or with the same named type applied to the same number of parameters \lstinline?C $T_{21}$ $\ldots$ $T_{2k}$? if the respective parameters \lstinline?$T_{1j}$? and \lstinline?$T_{2j}$? unify for all $j = 1, \ldots, k$. Universal  types unify only with type holes and should not appear in the set of constraints.

\begin{algorithm}
\caption{Type unification\label{alg:type unification}}
\KwIn{Set of constraints $\C = \{T_{11} = T_{12}, T_{21} = T_{22}, \ldots\}$}
\KwOut{Substitution $\sigma$ so that $\sigma(T_{i1}) = \sigma(T_{i2})$ for every constraint $T_{i1} = T_{i2}$ in $\C$}

\SetKwProg{Fn}{Function}{ is}{end}
\Fn{unify($\C$)}{
	\DontPrintSemicolon
	\lIf{$\C = \emptyset$}{
		[]
	}\Else{let $\{T_1 = T_2\} \cup \C' = \C$ in\\
		\uIf{$T_1 = T_2$}{
			\textit{unify}$(\C')$
		}\uElseIf{$T_1 = {?X}$ and ${?X}$ does not occur in $T_2$}{
			\textit{unify}$([?X \mapsto T_2]\C') \circ [?X \mapsto T_2]$
		}\uElseIf{$T_2 = {?X}$ and ${?X}$ does not occur in $T_1$}{
			\textit{unify}$([?X \mapsto T_1]\C') \circ [?X \mapsto T_1]$
		}\uElseIf{$T_1 = T_{11} \rightarrow T_{12}$ and $T_2 = T_{21} \rightarrow T_{22}$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}\})$
		}\uElseIf{$T_1 = C\;T_{11}\; T_{12}\; \ldots\; T_{1k}$ and $T_2 = C\; T_{21}\; T_{22}\; \ldots,\; T_{2k}$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}, \ldots, T_{1k} = T_{2k}\})$
		}\Else{
			\textit{fail}
		}
	}
}
\end{algorithm} 

\section{Search}
After defining the target language, the evaluation semantics, the type checking and the type unification, we are ready to formally define the problem.

\paragraph{Problem definition} Given a library $\Delta$, a goal type $T$ and a list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, find a closed term $t$ in the target language such that
\begin{enumerate}[(i)]
\item the abstraction of $t$ over all of its type and term input variables has the goal type under an empty variable binding context and an empty hole binding context, that is $\emptyset, \emptyset, \Phi_1, \Delta \vdash t' : T$ where $t'$ is \[\Lambda X_1.\; \ldots\; \Lambda X_j.\; \lambda x_1.\; \ldots\; \lambda x_k.\; [I_1 \mapsto X_1, \ldots, I_j \mapsto X_j, i_1 \mapsto x_1, \ldots, x_k \mapsto x_k]t.\]
\item $t$ satisfies all input-output examples, that is $\Phi_n, \Delta \vdash t \longrightarrow^* t'$ and $\Phi_n, \Delta \vdash o_n \longrightarrow^* t'$ for all $n = 1, \ldots, N$.
\end{enumerate}

In Section~\ref{Search space} we define the search space and in Section~\ref{Exploration} we describe the main enumeration algorithm, a standard best-first search.

\subsection{Search space}\label{Search space}
The search space is structured as a graph, where the vertices correspond to \emph{programs}. Recall that a program is the 4-tuple $\{\Xi, \Phi, \Delta \vdash t :: T'\}$, where $t$ is a term of the target language. The type $T'$ can be transformed into the goal type $T$ abstracting over all type and term input variables. That is, if $\Phi$ contains the type input variables $I_1, \ldots, I_j$ and the signatures of the term input variables $i_1 : T_1, \ldots, i_k : T_k$, then the goal type $T$ should be equal to
\[\forall X_1.\; \ldots \forall X_j.\; [I_1 \mapsto X_1, \ldots, I_j \mapsto X_j] (T_1 \rightarrow \ldots \rightarrow T_k \rightarrow T').\]

There is a directed edge between two programs $\{\Xi_1, \Phi, \Delta \vdash t_1 :: T'\}$ and $\{\Xi_2, \Phi, \Delta \vdash t_2 :: T'\}$ if and only if the judgement \emph{derive} (defined below) $\Xi, \Phi, \Delta \vdash t_1 :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_2 :: T_2$ holds between the two.

To express the rules of the derive judgement in a more compact form, we introduce \emph{evaluation contexts}. An evaluation context is an expression with exactly one syntactic hole $[]$ in which we can plug in any term. For example, if we have the context $\mathcal{E}$ we can place the term $t$ into its hole and denote this new term by $\mathcal{E}[t]$.

The derive judgement can be summarised by the following four rules.\\
D-VarLib replaces a hole $?x$ with a type application of a library component $c$ to suitable types, if the type of $c$ unifies with the type of $?x$. D-VarInp replaces a hole $?x$ with an input variable $i$ from the context $\Phi$, if its type unifies with the type of the hole. D-VarApp turns a hole into a term application of two fresh holes. The rule D-App chooses a hole in the program and expands it according to one of the three rules above.

The notation $\sigma(\Xi)$ denotes the application of the substitution $\sigma$ to all types appearing in $\Xi$.

\begin{prooftree}
\AxiomC{$c : \forall X_1.\; \ldots \forall X_n.\; T_c(X_1, \ldots, X_n) \in \Delta$}
\noLine
\UnaryInfC{$?X_1, \ldots, ?X_n$ are fresh type holes}
\noLine
\UnaryInfC{$\sigma$ unifies $T$ with $T_c(?X_1, \ldots, ?X_n)$}
\noLine
\UnaryInfC{$\Xi' = \Xi \cup \{{?X_1}, \ldots, {?X_n}\} \setminus \{{?x} : T\}$}
	\RightLabel{D-VarLib}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi'), \Phi, \Delta \vdash c\; [\sigma(?X_1)]\; \ldots\; [\sigma(?X_n)] :: \sigma(T) $
	}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i : T_i \in \Phi$}
\AxiomC{$\sigma$ unifies $T$ with $T_i$}
	\RightLabel{D-VarInp}
	\BinaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi \setminus \{{?x} : T\}), \Phi, \Delta \vdash i :: \sigma(T) $
	}
\end{prooftree}


\begin{prooftree}
\AxiomC{$?X$ is a fresh type variable}
\noLine
\UnaryInfC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{D-VarApp}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_1' :: T_1'$}
	\RightLabel{D-App}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}

All derived programs are well-typed and, since the types of all derived programs unify with the types of their ancestors, have the desired type.

\subsection{Best-first search}\label{Exploration}
Our enumeration procedure traverses the search graph defined in the previous section using a standard best-first search. The algorithm maintains a frontier of candidate programs and expands one hole of the most promising program in each iteration. Closed programs are evaluated on the input-output examples. The search terminates when the first program that satisfies all input-output examples is found.

Algorithm~\ref{alg:best-first search} is parametrised with respect to the following two questions.
\begin{enumerate}
\item Which candidate program is the most promising?
\item Which hole of the most promising program should be expanded?
\end{enumerate}
The first question is addressed by the implementation of the \lstinline?compare? function over programs. Section~\ref{Cost functions} discusses different approaches to define it.

The second question is addressed by the implementation of the \lstinline?successor? function. In particular, the implementation of the D-App rule. There are two easy ways to handle this problem. The first way is to always expand the leftmost hole, the second way is to always expand the oldest hole.

\begin{algorithm}
\caption{Best first search\label{alg:best-first search}}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$}
\KwOut{closed program $\{\Xi, \Phi_1, \Delta \vdash t :: T\}$ that satisfies all I/O-examples}

queue $\gets$ PriorityQueue.empty {\color{blue}compare}\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	successors $\gets$ {\color{blue}successor} (PriorityQueue.top queue)\\
	queue $\gets$ PriorityQueue.pop queue\\
	\For{all s in successors}{
		queue $\gets$ PrioriryQueue.push queue s\\
	}
}
\Return{PriorityQueue.top queue}
\end{algorithm}

\section{Cost functions}\label{Cost functions}
\TODO{General TODO: decide how do you want to call your cost functions. Now they are everywhere called nof-nodes, nof-nodes-simple-type and no-same-component. Maybe you want some simpler and shorter name.\\}
The compare function in the best-first search algorithm can be defined as \lstinline?cost $p_1$ - cost $p_2$?. There are different possibilities to define this cost function. We will present four alternatives. All of them are based on the idea that shorter and simpler programs generalise better to unseen examples, along the lines of the Occam's razor principle \cite{computationalLearningTheory}. The first three alternatives were evaluated on benchmarks and their effect on performance is discussed in Section~\ref{Eval. Cost functions}.

  \paragraph{nof-nodes}
The first cost function is based only on the number of nodes of the term. It prioritises shorter programs and prefers input variables over library components over holes.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes}(c) = 1$
$\textit{nof-nodes}({?x}) = 2$
$\textit{nof-nodes}(i) = 0$
$\textit{nof-nodes}(t_1\; t_2) = 1 + \textit{nof-nodes}(t_1) + \textit{nof-nodes}(t_2)$
$\textit{nof-nodes}(t\; [T]) = 1 + \textit{nof-nodes}(t)$
\end{lstlisting}
%
  \paragraph{nof-nodes-simple-type}
The second cost function also adds a factor based on the size of the types appearing in the term. It penalises thus terms with type application depending on the applied types. In particular, arrow types appearing in type applications are heavily penalised.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes-type}(X) = 1$
$\textit{nof-nodes-type}({?X}) = 0$
$\textit{nof-nodes-type}(I) = 0$
$\textit{nof-nodes-type}(C\; T_1\; \ldots\; T_k) = 0$
$\textit{nof-nodes-type}(T_1 \rightarrow T_2) = 3 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$

$\textit{nof-nodes-term}(c) = 1$
$\textit{nof-nodes-term}({?x}) = 2$
$\textit{nof-nodes-term}(i) = 0$
$\textit{nof-nodes-term}(t_1\; t_2) = 1 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$
$\textit{nof-nodes-term}(t\; [T]) = 1 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$

$\textit{nof-nodes-and-types}(t) = \textit{nof-nodes-term}(t)$
\end{lstlisting}

  \paragraph{no-same-component}
In the third cost function we additionally penalize terms that use the same component more than once.
%
\begin{lstlisting}[style=algorithm]
$\textit{nof-nodes-type}({?X}) = 3$
$\textit{nof-nodes-type}(I) = 0$
$\textit{nof-nodes-type}(C\; T_1\; \ldots\; T_k)$= $4 + \textit{nof-nodes-type}(T_1) + \ldots + \textit{nof-nodes-type}(T_k)$
$\textit{nof-nodes-type}(T_1 \rightarrow T_2) = 5 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$

$\textit{nof-nodes-term}(c) = 3$
$\textit{nof-nodes-term}({?x}) = 2$
$\textit{nof-nodes-term}(i) = 0$
$\textit{nof-nodes-term}(t_1\; t_2) = 6 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$
$\textit{nof-nodes-term}(t\; [T]) = 5 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$

$\textit{count}(t) = \displaystyle \sum_{c_i \text{ appears in } t} \text{(occurrences of } c_1 \text{ in } t) - 1$

$\textit{no-same-component}(t) = \textit{nof-nodes-term}(t) + 3\; \textit{count}(t)$
\end{lstlisting}

  \paragraph{string-length}
The simplest and most imprecise method to take both the number of nodes and the complexity of the types appearing in the term into account is to define the cost of a term as the length of the string representing that term. This method also allows a simple way to weight differently the various library components by choosing a shorter or longer name. However, we decided not to use this cost function for evaluation.

\section{Black list}\label{Black list}
Recall the 'replicate' example, where we saw the superfluous program \lstinline!const [?X] ?$x_1$ ?$x_2$!. The best-first enumeration explores many superfluous branches like \lstinline!foldr [?X] [List ?X] (cons [?X]) (nil [?X]) ?xs! or \lstinline!add zero ?n!. Such programs can be ruled out only based on the semantics of the library components. A simple way to prune those superfluous branches is to compile a list of undesired patterns and check each generated program against this list. This is what we call \emph{black list pruning}.

A black list is a list of terms of the target language. Programs that contain a subterm that matches a term from the black list are removed from the candidate programs and their successors are ignored.

The relation \textit{matches} over terms is inductively defined as follows.
\begin{algorithm*}
\textit{matches}$({?x},t)$\\
\textit{matches}$(i,t)$\\
\textit{matches}$(c,c)$\\
\textit{matches}$(t_1\; t_2,t_3\; t_4)$ if \textit{matches}$(t_1,t_3)$ and \textit{matches}$(t_2,t_4)$\\
\textit{matches}$(t_1\; [T_1],t_2\; [T_1])$ if \textit{matches}$(t_1,t_2)$\\
\end{algorithm*}
As you can see, holes and input variables in the black list match every subterm, a library component matches only itself, a term application matches a term application whose respective left- and right hand sides match and a type application matches a type application if the left hand sides match. Note that the types in a type application are completely ignored.

Pruning based on black lists can be easily integrated in Algorithm~\ref{alg:best-first search}. The result is shown in Algorithm~\ref{alg:blacklist pruning}, where the differences to the original best-first search are highlighted in blue.

\begin{algorithm}
\caption{Best first search with black list\label{alg:blacklist pruning}}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, black list $[b_1, \ldots , b_M]$}

queue $\gets$ PriorityQueue.empty compare\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	\uIf{{\color{blue}not ((PriorityQueue.top queue) contains subterm from black list)}}{
		successors $\gets$ successor (PriorityQueue.top queue)\\
		queue $\gets$ PriorityQueue.pop queue\\
		\For{all s in successors}{
			queue $\gets$ PrioriryQueue.push queue s\\
		}
	}\Else{
		queue $\gets$ PriorityQueue.pop queue\\
	}
}
\KwOut{PriorityQueue.top queue}
\end{algorithm}

In Section~\ref{Black list generation} we discuss how to synthesise such a black list automatically.

\section{Templates}\label{Templates}
In this section we present a slightly different way to explore the search space. The idea is to fix all higher-order components first, producing a \emph{template} for a program, and then fill in the remaining holes with input variables and first-order components. Since programs usually contain only a few higher-order components, the enumeration of templates takes less time than the enumeration of programs of comparable size. Moreover, templates encode well-known patterns of computation and impose meaningful constraints on the remaining holes. Therefore, it should be easy to find the desired program starting from the right template. This allows us to quickly abandon templates if no program satisfying the input-output examples is found within a short timeout.

Let us formally define a template and describe the procedure.

The library $\Delta$ is split into two contexts: $\Delta_h$, containing all higher-order components, and $\Delta_f$, containing the first-order ones. We also need to introduce a new kind of term: the \emph{delayed hole} $\underline{?x}$. This is a hole, whose instantiation is delayed to the first-order search. The context $\Xi$ binds, additionally to normal holes, delayed holes as well.
A \emph{template} is a term in the target language that may contain delayed holes but does not contain input variables. A template is called \emph{closed} if it does not contain holes (it may, however, contain delayed holes).

The synthesis procedure iterates between two phases: enumeration of templates and, as soon as a closed template is found, enumeration of programs as in Algorithm~\ref{alg:best-first search} using $\Delta_f$ for a limited period of time or until a program satisfying all input-output examples is found.

We additionally restrict the space by requiring a template to have no more than $M$ higher-order components and no more than $P$ delayed holes. Templates are enumerated according to the rules listed below. Those are very similar to the ones defined in Section~\ref{Search space}, except that we cannot instantiate a hole with an input variable but we can delay a hole. All the rules are modified to take into account the restriction on the number of components and the number of closed holes. In order to do this, we need to pass along $m$, the number of higher-order components in the term whose subterms we are traversing.

Analogously to D-VarLib, the rule G-VarLib instantiates a hole with a type application of a higher-order library components to the right types, if the type of the component unifies with the type of the hole. The rule G-VarDelay delays the instantiation of a hole to the first-order search. G-VarApp replaces a hole with a term application of two fresh holes. G-App expands one of the holes of the template according to one of the three rules listed above. Note that there are no rules to expand a delayed hole.

\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m < M$}
\noLine
\UnaryInfC{$c : \forall X_1.\; \ldots \forall X_n.\; T_c(X_1, \ldots, X_n) \in \Delta_h$}
\noLine
\UnaryInfC{$?X_1, \ldots, ?X_n$ are fresh type holes}
\noLine
\UnaryInfC{$\sigma$ unifies $T$ with $T_c(?X_1, \ldots, ?X_n)$}
\noLine
\UnaryInfC{$\Xi' = \Xi \cup \{{?X_1}, \ldots, {?X_n}\} \setminus \{{?x} : T\}$}
	\RightLabel{G-VarLib}
	\UnaryInfC{$\Xi, \Phi, \Delta_h \vdash {?x} :: T \Mapsto \sigma(\Xi'), \Phi, \Delta_h \vdash c\; [\sigma(?X_1)]\; \ldots\; [\sigma(?X_n)] :: \sigma(T) $
	}
\end{prooftree}

\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m \leq M$}
	\RightLabel{G-VarDelay}
	\UnaryInfC{$\Xi, \Phi, \Delta_h, m \vdash {?x} :: T \Mapsto \Xi \setminus \{{?x}:T\} \cup \{\underline{?x}:T\}, \Phi, \Delta_h, m \vdash {\underline{?x}} :: T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$|\Xi| < P$ and $m \leq M$}
\noLine
\UnaryInfC{$?X$ is a fresh type variable}
\noLine
\UnaryInfC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{G-VarApp}
	\UnaryInfC{$\Xi, \Phi, \Delta_h \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta_h \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_1' :: T_1'$}
	\RightLabel{G-App}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
