\lstset{style=plain}

\chapter{Top down type driven synthesis} \label{ch:definitions}

In this chapter we will formally define our type-directed top-down synthesis procedure. We will start with an intuitive description of the problem and move on to the formal definitions of the target programming language and the search space. Finally, we will define the synthesis procedure and present some enhancements.

\section{Problem}

\subsection{The 'replicate' example}

Recall the example from Chapter~\ref{ch:introduction} where we wanted to synthesise \lstinline?replicate?. As our synthesis procedure is type-driven and example-based, the user specifies a program by providing its type along with a few I/O-examples.\\
Let us specify \lstinline?replicate? as follows.
\begin{lstlisting}[style=plain]
replicate :: $\forall$X. Int -> X -> List X
replicate 3 1 = [1,1,1]
replicate 2 [] = [[],[]]
\end{lstlisting}

We also need a library of components, from which we are going to compose our program. Let us assume we have the standard list combinators \lstinline?map? and \lstinline?foldr? with \lstinline?enumTo?, the function that returns a list from $1$ up to its argument, and \lstinline?const?, that always returns its first argument, along with the list constructors \lstinline?cons? and \lstinline?[]? and the integer constructors \lstinline?succ? and \lstinline?0?. Even with so few library components, the search space is quite big.

The goal is to put together components from the library in order to get a list. More concretely, we fix \lstinline?X? to be a fixed input type variable, we fix \lstinline?n? to be an integer and \lstinline?x? to be a fixed input variable of type \lstinline?X?. Now the goal looks like
\begin{lstlisting}[style=plain]
replicate n x = ?p
?p :: List X
\end{lstlisting}, 
where \lstinline!?p! is a \emph{hole}, a new fresh variable whose type is known.

Which components can we use in order to get something of type \lstinline?List X?? We cannot use \lstinline?enumTo?, because it only produces a list of integers, but all other possibilities are open. We could either fold  with an interesting function, or map some function, or even use \lstinline?const? with a smart first argument. But the first and easiest thing that has the type \lstinline?List X? is \lstinline?[]?. That is, our first program looks as follows.
\begin{lstlisting}[style=plain]
replicate n x = []
?p = [] :: List X
\end{lstlisting}
This is a \emph{closed} program, that is, a program without holes that can be evaluated on the input-output examples. Alas, it does not satisfy any of them. Therefore we must try the other components. We have following possibilities to fill in the hole \lstinline!?p!.

\begin{lstlisting}[style=plain]
replicate n x = cons ?x ?xs
?p = cons ?x ?xs :: List X
?x :: X
?xs :: List X
\end{lstlisting}

\begin{lstlisting}[style=plain]
replicate n x = map ?f ?xs
?p = map ?f ?xs :: List X
?f :: ?Y -> X
?xs :: List ?Y
\end{lstlisting}
Here \lstinline!?Y! is a fresh type variable that will be instantiated with something later. As of now we have no idea about the type of the argument of \lstinline!?f!, we only know that it has to match the type of the elements of \lstinline!?xs!.

\begin{lstlisting}[style=plain]
replicate n x = foldr ?f ?init ?xs
?p = foldr ?f ?init ?xs :: List X
?f :: ?Y -> List X -> List X
?init :: List X
?xs :: List ?Y
\end{lstlisting}

\begin{lstlisting}[style=plain]
replicate n x = const ?xs ?s
?p = const ?xs ?s :: List X
?xs :: List X
?s :: ?Y
\end{lstlisting}

Now we take the most promising program and try to fill in one of its \emph{holes} (the fresh variables starting with \lstinline!?!).
Let us decide that the first one is the most promising. We now have two holes to fill in, a function that can take something and return an \lstinline?X? and a list of something. Note that it has to be possible for all possible instantiations of \lstinline?X? and note that we have only one value of type \lstinline?X?, namely \lstinline?x?, the second argument to \lstinline?replicate?.

What are the possibilities to instantiate \lstinline!?f!? Obviously, we cannot use \lstinline?map? or \lstinline?enumTo?, because they return lists. But all other possibilities are still open. We have to add following programs to our pool of possible solutions.

\begin{lstlisting}[style=plain]
replicate n x = map (foldr ?g ?init) ?xs
?p = map ?f ?xs :: List X
?f = foldr ?g ?init :: List ?Z -> X
?g :: ?Z -> X -> X
?init :: X
?xs :: List (List ?Z)
\end{lstlisting}
Note that we instantiated \lstinline!?Y! with \lstinline!List ?Z!, because \lstinline?foldr? takes a list as its last argument.

\begin{lstlisting}[style=plain]
replicate n x = map (const ?x) ?xs
?f = const ?x :: ?Y -> X
?x :: X
?xs :: List ?Y
\end{lstlisting}

As you noticed, we maintain a frontier of programs with holes and expand one of the holes of the most promising program. Let us do it again. From the $6$ programs generated so far we choose the most promising one. Let us decide that it is the last one.
It has two holes to fill in. For the first hole, \lstinline!?x!, we have only one possibility. As this hole must be of type \lstinline?X?, the only thing we can take is the second argument of \lstinline?replicate?, \lstinline?x?.

\begin{lstlisting}[style=plain]
replicate n x = map (const x) ?xs
?p = map ?f ?xs :: List X
?f = const ?x :: ?Y -> X
?x = x :: X
?xs :: List ?Y
\end{lstlisting}

Let us directly decide that this is the most promising program so far. Later, in Section~\ref{Cost functions}, we will define cost functions of programs and define the most promising program to be the one with the smallest cost. For now we just choose the one that will lead us to the solution.

Like in the beginning, we have to generate a list. However, since this time the type of the elements is not fixed, we cannot rule out  \lstinline?enumTo?.
Therefore we have a lot of possibilities, starting with \lstinline?replicate n x = map (const x) []?, where we instantiate \lstinline!?xs! with \lstinline?[]?, and ending with

\begin{lstlisting}[style=plain]
replicate n x = map (const x) (enumTo ?n)
?p = map ?f ?xs :: List X
?f = const ?x :: ?Y -> X
?x = x :: X
?xs = enumTo ?n :: List Int
?n :: Int
\end{lstlisting}

First, we are going to evaluate the closed program \lstinline?replicate n x = map (const x) []?. This program does not satisfy any of the input-output examples too.

The next step is to expand one of the holes of the most promising program, let us decide that it is the last one. That is, we are looking for an integer. An integer can either be the constructor \lstinline?0?, or the constructor \lstinline?succ? applied to some integer hole, the first argument of \lstinline?replicate?, \lstinline?n?, or \lstinline?const? with some clever first argument applied to something.

Notice that among the new programs there are two closed programs, \lstinline?replicate n x = map (const x) (enumTo 0)? and \lstinline?replicate n x = map (const x) (enumTo n)?. Evaluation shows that only the second one satisfies the I/O-examples.

\subsection{Concepts}

This example shows some important concepts that are defined formally in the next sections of this chapter.
\begin{itemize}
\item Hole: unknown part of a program that can be instantiated with some other programs. Only its type is known.
\item Closed program: a program without holes that can be evaluated on the input-output examples. The terms and the types of our calculus are formally defined in Section~\ref{Term and types}.
\item Type-aware expansion of holes: we expand holes based on their type. In Section~\ref{Search space} we can find the rules according to which a program is expanded.
\item Best first search: a frontier of programs with holes is maintained, one hole of the most promising is expanded in every iteration. The best first search algorithm is defined in Section~\ref{Exploration} and a notion of most promising program is presented in Section~\ref{Cost functions}.
\item Superfluous program: a program that is equivalent to a simpler program. For example, a human programmer would not instantiate a hole with \lstinline!const ?x ?y!, because he could have written just \lstinline!?x! instead, which is always a shorter and preferable program. Section~\ref{Black list} shows one way to rule out superfluous programs.
\end{itemize}
 
\section{Calculus}
In this section we will introduce three different calculus.
\begin{itemize}
\item System F as in the excellent book of Pierce \cite{pierce2002types}
\item The system we derive from System F and in which the components are defined (includes holes, input variables and recursion for terms and types)
\item A subset of the second system, used for generation (only application of components, holes or input variables is allowed).
\end{itemize}
The exposition will closely follow  Pierce \cite{pierce2002types}.

Let's start with the standart System F.
Our calculus is based on System F. A subset of our calculus is used for generation.

\begin{itemize}
\item generate programs from restricted calculus
\item calculus itself is still powerful, because we use it to define the library components as well.
\end{itemize}


  \subsection{Terms and Types}\label{Term and types}
\begin{itemize}
\item similar to Pierce
\item except holes, components and free variables
\item recursion
\item recursive types that can take parameters
\item the search space is not the whole language but only a subset of it
\end{itemize}

Real System F
 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T]\\
(types): T ::= X | T \rightarrow T | \forall X.\; T\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
\end{plstx}

We use an extension of System F featuring holes $?x$, input variables $i$ as well as named library components $c$ and named types $C$. The use of the names enables recursion in the definition of library components and types. Named types also support type parameters. The number of type parameters supported by a named type is denoted as $K$ in its definition.

Question: where is the output? Can you define input and output pairs?
Our system
 \begin{plstx}
(terms): t ::= x | \lambda x : T.\; t | t\;t | \Lambda X.\; t | t\;[T] | c | {?x} | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\;[T,\ldots, T]\\
(variable bindings): \Gamma ::= \emptyset | \Gamma \cup \{x : T\} | \Gamma \cup \{X\}\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T : K\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}

Question: do we need the definitions of library components for synthesis? We use them only for evaluation, but we always evaluate programs during synthesis. Same for the input variables. Actually, for each I/O-example we get the pair $(\Phi,o)$, where $\Phi$ instantiates all input variables and input types of a program and $o$ is the expected output.
Subset of our system that builds the search space
 \begin{plstx}
(terms): t ::= t\;t | t\;[T] | c | ?x | i\\
(types): T ::= X | T \rightarrow T | \forall X.\; T | ?X | I | C\;[T,\ldots, T]\\
(hole bindings): \Xi ::= \emptyset | \Xi \cup \{{?x} : T\} | \Xi \cup \{{?X}\}\\
(input variable bindings): \Phi ::= \emptyset | \Phi \cup \{i = t : T\} | \Phi \cup \{I = T : K\}\\
(library components): \Delta ::= \emptyset | \Delta \cup \{c = t : T\} | \Delta \cup \{C = T : K\}\\
\end{plstx}


A program is the quadriplet $\{\Xi, \Phi, \Delta \vdash t :: T\}$. 
A term is called \emph{closed} if it does not contain holes.
A program is closed, if $\Xi$ is empty and $t$ and $T$ do not contain holes.


  \subsection{Encodings}
Note that in the definition of types we do not see familiar types such as booleans, integers, lists or trees. All these types can be encoded in System F using either the Church's or the Scott's encoding \cite{ScottNumerals}. We opted for the Scott's encoding because it's more efficient in our case.
Scott's booleans coincide with Church's booleans and are encoded as follows.
\begin{lstlisting}[style=plain, mathescape]
Bool  = $\forall$R. R $\rightarrow$ R $\rightarrow$ R
true  = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_1$
      : Bool
false = $\Lambda$R. $\lambda x_1$:R. $\lambda x_2$:R. $x_2$
      : Bool
if-then-else = $\Lambda$X. $\lambda$b:Bool. $\lambda$t:X. $\lambda$f:X. b [X] t f
             : $\forall$X. Bool $\rightarrow$ X $\rightarrow$ X $\rightarrow$ X
\end{lstlisting}

Scott's integers differ from Church's integers as they are more suitable for pattern matching. \note{because they don't unwrap the whole integer every time.}
\begin{lstlisting}[style=plain, mathescape]
Int = $\forall$R. R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
zero = $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. z
     : Int
succ = $\lambda$ n:Int. $\Lambda$R. $\lambda$z:R. $\lambda$s:Int $\rightarrow$ R. s n
     : Int $\rightarrow$ Int
case = $\Lambda$R. $\lambda$n:Int. $\lambda$a:R. $\lambda$f:Int $\rightarrow$ R. n [R] a f
     : $\forall$R. Int $\rightarrow$ R $\rightarrow$ (Int $\rightarrow$ R) $\rightarrow$ R
\end{lstlisting}

Analogously, Scott's lists are a recursive type and naturally support pattern matching.
\begin{lstlisting}[style=plain, mathescape]
List X = $\forall$R. R $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ R) $\rightarrow$ R
nil = $\Lambda$X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. n
    : $\forall$X. List X
con = $\Lambda$X. $\lambda$x:X. $\lambda$xs:List X. $\Lambda$R. $\lambda$n:R. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ R. c x xs
    : $\forall$X. X $\rightarrow$ List X $\rightarrow$ List X
case = $\Lambda$X. $\Lambda$Y. $\lambda$l:List X. $\lambda$n:Y. $\lambda$c:X $\rightarrow$ List X $\rightarrow$ Y. l [Y] n c
     : $\forall$X. $\forall$Y. List X $\rightarrow$ Y $\rightarrow$ (X $\rightarrow$ List X $\rightarrow$ Y) $\rightarrow$ Y
\end{lstlisting} 
 
  \subsection{Evaluation semantics}

In this section we present the evaluation semantics of our extended System F, that is the second calculus introduced in Section~\ref{Term and types}. The evaluation semantics is a standard eager evaluation and we refer to the excellent book of Benjamin Pierce about type systems \cite{pierce2002types} for an introduction to the evaluation semantics of System F and evaluation rules in general.

The evaluation judgement $\Phi, \Delta \vdash t \longrightarrow t'$ means that the term $t$ evaluates in one step to the term $t'$ under the free variable bindings library $\Phi$, that contains concrete instantiations for the input variables, and the component library $\Delta$ , that contains the definitions of the library components. Before listing the evaluation rules, let us define \emph{value} $v$ to be a term to which no evaluation rule apply.

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{E-Lib}
	\UnaryInfC{$\Phi, \Delta \vdash c \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{E-Inp}
	\UnaryInfC{$\Phi, \Delta \vdash i \longrightarrow t$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_1 \longrightarrow t_1'$}
	\RightLabel{E-App1}
	\UnaryInfC{$\Phi, \Delta \vdash t_1\; t_2 \longrightarrow t_1'\; t_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Phi, \Delta \vdash t_2 \longrightarrow t_2'$}
	\RightLabel{E-App2}
	\UnaryInfC{$\Phi, \Delta \vdash v_1\; t_2 \longrightarrow v_1\; t_2'$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{E-AppAbs}
	\UnaryInfC{$\Phi, \Delta \vdash (\lambda x:T_{11}.\; t_{12})\; v_2 \longrightarrow [x \mapsto v_2]t_{12}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
	\RightLabel{\textsc{E-AppAbs}}
	\UnaryInfC{$\Phi, \Delta \vdash (\Lambda X.\; t_2)\; [T_2] \longrightarrow [X \mapsto T_2]t_2$}
\end{prooftree}  
  
Rules E-Lib and E-Inp load the definitions of library components or input variables from the respective library. E-App1 and E-App2 evaluate the left hand side, respectively the right hand side, of an application. E-AppAbs and \textsc{E-AppAbs} get rid of an abstraction and substitute the argument into the body.\\
Note that E-App2 applies only if the left hand side of the application cannot be evaluated further and that E-AppAbs applies only when the argument of the lambda abstraction is a value, determining the order of evaluation.

\subsection{Type checking}

In this sections we will present the typing rules of our extended System F, that is the second calculus presented in Section~\ref{Term and types}. The typing judgement $\Gamma, \Xi, \Phi, \Delta \vdash t : T$ means the term $t$ has type $T$ in the contexts $\Gamma$ and $\Xi$, binding respectively variables and holes, and $\Phi$ and $\Delta$, containing signatures and definitions of respectively input variables and library components. The typing judgement is similar to the typing judgement of System F presented in the book about type systems of Benjamin Pierce \cite{pierce2002types} and we refer to the book for more details.
  
\begin{prooftree}
\AxiomC{$x : T \in \Gamma$}
	\RightLabel{T-Var}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash x : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{${?x} : T \in \Xi$}
	\RightLabel{T-Hol}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash {?x} : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i = t : T \in \Phi$}
	\RightLabel{T-Inp}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash i : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$c = t : T \in \Delta$}
	\RightLabel{T-Lib}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash c : T$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{x : T_1\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{T-Abs}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \lambda x : T_1.\; t_2 : T_1 \rightarrow T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : T_1 \rightarrow T_2$}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_2 : T_1$}
	\RightLabel{T-App}
	\BinaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;t_2 : T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \cup \{X\}, \Xi, \Phi, \Delta \vdash t_2 : T_2$}
	\RightLabel{\textsc{T-Abs}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash \Lambda X.\; t_2 : \forall X.\; T_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1 : \forall X.\; T_{12}$}
	\RightLabel{\textsc{T-App}}
	\UnaryInfC{$\Gamma, \Xi, \Phi, \Delta \vdash t_1\;[T_2] : [X \mapsto T_2]T_{12}$}
\end{prooftree}

The rules T-Var, T-Hol, T-Inp and T-Lib load the signature of variables, holes, input variables or library components from the respective context.
T-Abs types a lambda abstraction as an arrow type from the type of its variable to the type of its body. \textsc{T-Abs} gives a type abstraction as a universal type in accordance to the type of its body.
An application typechecks only if the left hand side has an arrow type and the type of the argument is equal to the type of the argument of the left hand side. Analogously, a type application typechecks only if the left hand side has a universal type.

\subsection{Type unification}
\TODO{Write this\\}

Since unification on System F types is undecidable \cite{Huet1975}, we decided to do something simpler. Explain what. Boom, fertig, party.

The unification algorithm is based on the unification algorithm for typed lambda calculus from the book of Pierce \TODO{cite the book properly!!!} and slightly modified to fit our needs.
  
How did you do type unification?
Unification of universal types is not implemented. If you need to unify to universal types, you should transform all bound variables into holes and remove the universal quantifier.

A set of constraints is a set of types that should be equal under a substitution. The unification algorithm is supposed to output a substitution $\sigma$ so that $\sigma(S) = \sigma(T)$ for every constraint $S = T$ in $\C$.

\begin{algorithm}
\caption{Type unification}
\KwIn{Set of constraints $\C = \{T_{11} = T_{12}, T_{21} = T_{22}, \ldots\}$}
\KwOut{Substitution $\sigma$ so that $\sigma(T_{i1}) = \sigma(T_{i2})$ for every constraint $T_{i1} = T_{i2}$ in $\C$}

\SetKwProg{Fn}{Function}{ is}{end}
\Fn{unify($\C$)}{
	\DontPrintSemicolon
	\lIf{$\C = \emptyset$}{
		[]
	}\Else{let $\{T_1 = T_2\} \cup \C' = \C$ in\\
		\uIf{$T_1 = T_2$}{
			\textit{unify}$(\C')$
		}\uElseIf{$T_1 = {?X}$ and ${?X}$ does not occur in $T_2$}{
			\textit{unify}$([X \mapsto T_2]\C') \circ [X \mapsto T_2]$
		}\uElseIf{$T_2 = {?X}$ and ${?X}$ does not occur in $T_1$}{
			\textit{unify}$([X \mapsto T_1]\C') \circ [X \mapsto T_1]$
		}\uElseIf{$T_1 = T_{11} \rightarrow T_{12}$ and $T_2 = T_{21} \rightarrow T_{22}$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}\})$
		}\uElseIf{$T_1 = C\;[T_{11}, T_{12}, \ldots, T_{1k}]$ and $T_2 = C\;[T_{21}, T_{22}, \ldots, T_{2k}]$}{
			\textit{unify}$(\C' \cup \{T_{11} = T_{21}, T_{12} = T_{22}, \ldots, T_{1k} = T_{2k}\})$
		}\Else{
			\textit{fail}
		}
	}
}
\end{algorithm} 

\section{Search}
how do we explore the search space (best-first search).
\subsection{Search space}\label{Search space}
Use only third system presented in Section System F.

Formal problem definition. Given a library $\Delta$, a goal type $T$ and a list of I/O-examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, find a closed term $t$ so that $\emptyset, \emptyset, \Phi_1, \Delta \vdash t : T$ (that is, $t$ has the goal type under an empty variable binding context and an empty hole binding context) and $t$ satisfies all I/O-examples, that is $\Phi_n, \Delta \vdash t \longrightarrow^* \vdash t'$ and $\Phi_n, \Delta \vdash o_n \longrightarrow^* \vdash t'$ for all $n = 1, \ldots, N$.

We see the search space as a graph of programs with holes (see third syntax presented in Section System F) where there is an edge between two terms $t_1$ and $t_2$ if and only if the judgement \emph{derive} defined below $\Xi, \Phi, \Delta \vdash t_1 :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_2 :: T_2$ holds between the two.

To express the rules in a more compact form, we introduce \emph{evaluation contexts}. An evaluation context is an expression with exactly one syntactic hole $[]$ in which we can plug in any term. For example, if we have the context $\mathcal{E}$ we can place the term $t$ into its hole and denote this new term by $\mathcal{E}[t]$.

A hole $?x$ can be turned into a library component $c$ from the context $\Delta$ or an input variable $i$ from the context $\Phi$. The procedure fresh($T$) transforms universally quantified type variables into fresh type variables $?X$ not used in $\Xi$.
The notation $\sigma(\Delta)$ denotes the application of the substitution $\sigma$ to all types contained in the context $\Delta$.

\begin{prooftree}
\AxiomC{$c : T_c \in \Delta$}
\AxiomC{$\sigma$ unifies $T$ with fresh($T_c$)}
	\RightLabel{D-VarLib}
	\BinaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi \setminus \{{?x} : T\}), \Phi, \Delta \vdash c :: \sigma(T) $
	}
\end{prooftree}

\begin{prooftree}
\AxiomC{$i : T_i \in \Phi$}
\AxiomC{$\sigma$ unifies $T$ with fresh($T_i$)}
	\RightLabel{D-VarInp}
	\BinaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \sigma(\Xi \setminus \{{?x} : T\}), \Phi, \Delta \vdash i :: \sigma(T) $
	}
\end{prooftree}

A hole can also be turned into a function application of two new active holes.
\begin{prooftree}
\AxiomC{$?X$ is a fresh type variable}
\AxiomC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{D-VarApp}
	\BinaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}

In all other cases we just choose a hole and expand it according to the three rules above.
\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta \vdash t_1' :: T_1'$}
	\RightLabel{D-App}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}

Note that the types of all successor programs unify with the types of their ancestors. Thus, the search is type directed. Only programs of the right type are generated.


\subsection{Exploration}\label{Exploration}
  \note{Write also about stack vs queue of open holes}

We explore the search graph using a best first search.
We can play with the algorithm in two points (marked in blue): first, we can define which hole to expand first, second, we can choose the compare function of the priority queue.
Different approaches to define the \lstinline?compare? function are discussed in the next session.
Concerning the order of expansion of the holes, we tried two strategies: the first one was maintaining a stack of holes ($\Xi$ implemented as a stack), which leads to the expansion of the deepest hole first, the second one was maintaining a queue of holes ($\Xi$ implemented as a queue), which leads to the expansion of the oldest hole first.

\begin{algorithm}
\caption{Best first search}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$}
\KwOut{closed program $\{\Xi, \Phi_1, \Delta \vdash t :: T\}$ that satisfies all I/O-examples}

queue $\gets$ PriorityQueue.empty {\color{blue}compare}\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	successors $\gets$ {\color{blue}successor} (PriorityQueue.top queue)\\
	queue $\gets$ PriorityQueue.pop queue\\
	\For{all s in successors}{
		queue $\gets$ PrioriryQueue.push queue s\\
	}
}
\Return{PriorityQueue.top queue}
\end{algorithm}

\section{Cost functions}\label{Cost functions}

The compare function in the best first search algorithm is \lstinline?cost $p_1$ - cost $p_2$?. There are different possibilities to implement this cost function. We will present four alternatives.

  \paragraph{number of nodes}
The first cost function is based only on the number of nodes of the term. Longer and more complicated terms are disadvantaged.
%
\begin{algorithm}
\caption{Cost function based on the number of nodes}
\KwIn{term $t$}
\KwOut{weighted number of nodes in $t$}

\textit{nof-nodes}$(c) = 1$\\
\textit{nof-nodes}$({?x}) = 2$\\
\textit{nof-nodes}$(i) = 0$\\
\textit{nof-nodes}$(x) = 1$\\
\textit{nof-nodes}$(\lambda x : T.\; t) = 1 + \textit{nof-nodes}(t)$\\
\textit{nof-nodes}$(t_1\; t_2) = 1 + \textit{nof-nodes}(t_1) + \textit{nof-nodes}(t_2)$\\
\textit{nof-nodes}$(\Lambda X.\; t) = 1 + \textit{nof-nodes}(t)$\\
\textit{nof-nodes}$(t\; [T]) = 1 + \textit{nof-nodes}(t)$\\

\end{algorithm} 
%
  \paragraph{number of nodes and types}
The second cost function also adds a factor based on the types appearing in the term, thus penalizing terms with type application and very complicated types.
%
\begin{algorithm}
\caption{Cost function based on the number of nodes and types}
\KwIn{term $t$}
\KwOut{sum of weighted number of nodes in term $t$ and weighted number of nodes in the types appearing in $t$}

\textit{nof-nodes-type}$(X) = 1$\\
\textit{nof-nodes-type}$({?X}) = 0$\\
\textit{nof-nodes-type}$(I) = 0$\\
\textit{nof-nodes-type}$(C\; [T_1, \ldots, T_k]) = 0$\\
\textit{nof-nodes-type}$(T_1 \rightarrow T_2) = 3 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$\\
\textit{nof-nodes-type}$(\forall X.\; T) = 1 + \textit{nof-nodes-type}(T)$\\

\BlankLine

\textit{nof-nodes-term}$(c) = 1$\\
\textit{nof-nodes-term}$({?x}) = 2$\\
\textit{nof-nodes-term}$(i) = 0$\\
\textit{nof-nodes-term}$(x) = 1$\\
\textit{nof-nodes-term}$(\lambda x : T.\; t) = 1 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$\\
\textit{nof-nodes-term}$(t_1\; t_2) = 1 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$\\
\textit{nof-nodes-term}$(\Lambda X.\; t) = 1 + \textit{nof-nodes-term}(t)$\\
\textit{nof-nodes-term}$(t\; [T]) = 1 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$\\

\BlankLine

\textit{nof-nodes-and-types}$(t) = \textit{nof-nodes-term}(t)$
\end{algorithm} 
%

  \paragraph{no same component}
In the third function we additionally penalize terms using the same component more than once.
%
\begin{algorithm}[h]
\caption{Cost function based on the number of nodes and types penalizing the use of a library component more than once}
\KwIn{term $t$}
\KwOut{sum of the weighted number of nodes in term $t$, the weighted number of nodes in the types appearing in $t$ and the weighted number of library components appearing more than once in $t$.}

\textit{nof-nodes-type}$(X) = 10$\\
\textit{nof-nodes-type}$({?X}) = 3$\\
\textit{nof-nodes-type}$(I) = 0$\\
\textit{nof-nodes-type}$(C\; [T_1, \ldots, T_k])$= $4 + \textit{nof-nodes-type}(T_1) + \ldots + \textit{nof-nodes-type}(T_k)$\\
\textit{nof-nodes-type}$(T_1 \rightarrow T_2) = 5 + \textit{nof-nodes-type}(T_1) + \textit{nof-nodes-type}(T_2)$\\
\textit{nof-nodes-type}$(\forall X.\; T) = 10 + \textit{nof-nodes-type}(T)$\\

\BlankLine

\textit{nof-nodes-term}$(c) = 3$\\
\textit{nof-nodes-term}$({?x}) = 2$\\
\textit{nof-nodes-term}$(i) = 0$\\
\textit{nof-nodes-term}$(x) = 10$\\
\textit{nof-nodes-term}$(\lambda x : T.\; t) = 10 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$\\
\textit{nof-nodes-term}$(t_1\; t_2) = 6 + \textit{nof-nodes-term}(t_1) + \textit{nof-nodes-term}(t_2)$\\
\textit{nof-nodes-term}$(\Lambda X.\; t) = 10 + \textit{nof-nodes-term}(t)$\\
\textit{nof-nodes-term}$(t\; [T]) = 5 + \textit{nof-nodes-term}(t) + \textit{nof-nodes-type}(T)$\\

\BlankLine

\textit{count}$(t) = \displaystyle \sum_{c_i \text{ appears in } t} \text{(occurrences of $c_1$ in $t$)} - 1$\\
%sum of the number of times minus one a component $c_i$ appears in $t$ for each component $c_i$ appearing in $t$.\\
%number of all occurrences of library components in $t$ minus the number of different components appearing in $t$.

\BlankLine

\textit{no-same-component}$(t) = \textit{nof-nodes-term}(t) + 3\; \textit{count}(t)$
\end{algorithm} 
%

  \paragraph{length of the string}
The simplest and most imprecise method to take both the number of nodes and the complexity of the types appearing in the term is taking the length of the string of that term.

\section{Black list}\label{Black list}
  \note{automatic generation of black list discussed in evaluation}
A black list is a list of terms. Programs containing a black term as a subterm are not allowed to have successors. Thus, the algorithm above is modified as follows.

\begin{algorithm}
\caption{Best first search with black list}
\KwIn{goal type $T$, library components $\Delta$, list of input-output examples $[(\Phi_1, o_1), \ldots , (\Phi_N, o_N)]$, black list $[b_1, \ldots , b_M]$}

queue $\gets$ PriorityQueue.empty compare\\
queue $\gets$ PriorityQueue.push queue $\{\Xi, \Phi_1, \Delta \vdash {?x} :: T\}$\\

\While{not ((PriorityQueue.top queue) satisfies all I/O-examples)}{
	\uIf{{\color{blue}not ((PriorityQueue.top queue) contains subterm from black list)}}{
		successors $\gets$ successor (PriorityQueue.top queue)\\
		queue $\gets$ PriorityQueue.pop queue\\
		\For{all s in successors}{
			queue $\gets$ PrioriryQueue.push queue s\\
		}
	}\Else{
		queue $\gets$ PriorityQueue.pop queue\\
	}
}
\KwOut{PriorityQueue.top queue}
\end{algorithm}

One could use the synthesis algorithm presented in Section \ref{Exploration} to automatically synthesise black lists. For example,  one could synthesise many programs corresponding to the identity function or to the empty list or to any other term, and add all those programs but one to the black list.

\section{Templates}\label{Templates}
  Top-down type-driven synthesis.

A template is a program with holes. We are interested in templates where all higher-order components are fixed and there are holes for the first-order components.
The search space is thus similar to the search space described in \ref{Search space}, with the exception that $\Delta$ contains only the higher-order components.
One of the new things are \emph{closed holes} $\underline{?x}$. Those are holes that are supposed to be filled in later with first-order components.

The idea behind the templates is that once the higher-order components are fixed, it should be easy and fast to find a first-order assignment to get the right program. So we could do a limited search from a template and if we do not find a program satisfying all of the I/O-examples we can move quickly to the next template.

We additionally restrict the space by requiring a template to have no more than $M$ higher-order components and no more than $P$ closed holes.

  \subsection{Successor rules}

The successor rules are very similar to the ones defined in \ref{Search space}, apart from little modifications. That is, now we have a successor rule to close a hole, and we can not instantiate a hole with an input variable any more, because that is supposed to be done in the next step. All the rules are modified to take into account the restriction on the number of components and the number of closed holes. In order to do this, we need to pass along $m$, the number of higher-order components in the term whose subterms we are traversing.


So we can \emph{close} a hole.
\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m \leq M$}
\noLine
\UnaryInfC{$T$ is a type a first-order component can have}
	\RightLabel{G-VarClose}
	\UnaryInfC{$\Xi, \Phi, \Delta, m \vdash {?x} :: T \Mapsto \Xi, \Phi, \Delta, m \vdash {\underline{?x}} :: T$}
\end{prooftree}

We can instantiate a hole with a (higher-order) library component.
\begin{prooftree}
\AxiomC{$|\Xi| \leq P$ and $m < M$}
\noLine
\UnaryInfC{$c = t_c : T_c \in \Delta$}
\noLine
\UnaryInfC{$\sigma$ unifies $T$ with fresh($T_c$)}
	\RightLabel{G-VarLib}
	\UnaryInfC{$\Xi, \Phi, \Delta, m \vdash {?x} :: T \Mapsto \sigma(\Xi \setminus \{{?x} : T\}), \Phi, \Delta, m+1 \vdash c :: \sigma(T) $
	}
\end{prooftree}

We can instantiate a hole with a function application of two fresh holes.
\begin{prooftree}
\AxiomC{$|\Xi| < P$ and $m \leq M$}
\noLine
\UnaryInfC{$?X$ is a fresh type hole, $?x_1$ and $?x_2$ are fresh term holes}
\noLine
\UnaryInfC{$\Xi' = {\Xi \setminus \{?x:T\} \cup \{{?x_1} : {?X} \rightarrow T, {?x_2} : {?X}, {?X}\}}$}
	\RightLabel{G-VarApp}
	\UnaryInfC{$\Xi, \Phi, \Delta \vdash {?x} :: T \Mapsto \Xi', \Phi, \Delta \vdash {?x_1}\;{?x_2} :: T$}
\end{prooftree}

We can expand one of the holes of the program according to one of the three rules above.
\begin{prooftree}
\AxiomC{$\Xi, \Phi, \Delta, m \vdash {?x} :: T_1 \Mapsto \Xi', \Phi, \Delta, m' \vdash t_1' :: T_1'$}
	\RightLabel{G-App}
	\UnaryInfC{$\Xi, \Phi, \Delta, m \vdash t[{?x}] :: T \Mapsto \Xi', \Phi, \Delta, m' \vdash t[t_1] :: [T_1 \mapsto T_1']T$}
\end{prooftree}


  




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
