\chapter{Conclusions} \label{ch:conclusions}

\section{Conclusions}

Type-driven synthesis of functional programs from input-output examples   strives to automatically generate well-typed programs that satisfy the given input-output examples and generalise well to unseen input-output pairs. When solving similar tasks, human programmers rely on well-known computational patterns.

%\TODO{Do we need the example at all?\\}
%Consider, for example, a human is given the task to write \lstinline!replicate!, the function that takes an integer \lstinline!n! and an element \lstinline!x! and returns the list \lstinline![x, x, $\ldots$, x]! of \lstinline!n! copies of \lstinline!x!. The human would probably resort to recursion over integers. That is, depending on the value of \lstinline!n!, she would either call \lstinline!replicate (n-1) x! and prepend the result with another \lstinline!x! or, if \lstinline!n! is $0$, return the empty list:
%\begin{lstlisting}[style=plain]
%replicate 0 x = []
%replicate n x = x:(replicate (n-1) x)
%\end{lstlisting}
%This computational pattern is expressed by \lstinline!foldNat!, the higher-order component that folds an integer using a given function. That is, the above program is equivalent to:
%\begin{lstlisting}[style=plain]
%replicate n x = foldNat (x:) [] n
%\end{lstlisting}

The main goal of this thesis was to study how well first- and higher-order components can guide and speed up the synthesis process.

In order to achieve this goal, we implemented a prototype of a simple synthesis procedure based on program enumeration in OCaml. Extensive evaluation of the prototype on benchmarks showed that it can compete with related state-of-the-art tools. We believe therefore that synthesis from library components is a promising direction and needs to be explored further.

The prototype implements a synthesis procedure based on best-first enumeration of partial programs. We experimented with different cost functions and with different strategies to expand a partial program.

\subsection{Observations about the search space}\label{observations}
During experimentation we faced different classes of programs that hinder the synthesis process.

First of all, we discovered that the search space abounds of closed programs that represent a challenge for our evaluator, even on examples as small as \lstinline![2,2,3]! and \lstinline!3!. This was our main motivation in reducing the size and the number of input-output examples.

Next, we noticed that every hole can be filled in with \lstinline!head [?X] (nil [?X])!, where \lstinline!?X! has to be instantiated with the type of the hole to expand. Many partial programs containing this pattern were enumerated just to be ruled out as soon as all holes were filled in and the closed programs were evaluated. To prune whole branches that will surely not lead to a solution, we introduced a black list containing the undesired patterns. As a next step, we used the synthesiser to generate such a black list automatically.

A related problem are partial programs that can be ruled out based on the semantics of the library component and the expected behaviour of the target program. For example, when trying to synthesise \lstinline!enumFromTo!, no human programmer would insist on taking \lstinline!enumTo! as the first component. The partial program
\begin{lstlisting}[style=plain]
enumFromTo m n = enumTo ?x
\end{lstlisting}
will not lead to the solution, because every list returned by \lstinline!enumTo!, no matter the argument, starts with $1$, whereas the list returned by \lstinline!enumFromTo! should start with \lstinline!m!, which is not necessarily $1$. Our synthesis procedure, on the contrary, treats this partial program and its successors as very promising candidates.
This motivated us to try a slightly different synthesis procedure: the one that fixes the higher-order components first (generating a \emph{template}) and then fills in the remaining holes with input variables and first-order components.

Empirical evaluation showed that reducing the size of the examples and blacklisting undesired patterns improves the performance, as expected. On the other hand---against expectations---the introduction of templates leads to a significant slowdown. We believe, however, that this could be changed with a more sophisticated implementation and should be investigated further.


\section{Future Work}

As anticipated in the previous section, the information about well-known computational patterns encoded as library components can be successfully reused in program synthesis. However, in order to reach a publishable unit, this promising direction needs further exploration. In this section we list some possibilities for future work that follow from the limitations of our system.

\subsection{Automatic black list generation}
Pruning based on black lists helps to reduce synthesis time. However, manually compiled black lists are inconvenient when users are allowed to add their own components to the library. Automatically synthesising a black list from the components in the given library would alleviate this inconvenience.

In Section~\ref{Black list generation} we discussed how we used our synthesis procedure to automatically generate a black list. However, we arrived at the conclusion that our method is too primitive to compete with a manually compiled black list. In particular, the generated patterns have only one wild-card and correspond to the identity function. The former restriction leads to the generation of patterns like
\begin{lstlisting}[style=plain]
foldr append _ nil
foldr con _ nil
foldr drop nil
\end{lstlisting}
that we would like to replace with the single pattern \lstinline!foldr _ _ nil!. The more general pattern not only helps keep the size of the black list small but also rules out more of the superfluous programs.
The latter restriction prevents us from generating longer synonyms for terms like \lstinline!nil! and \lstinline!zero! that do not involve the application of the identity function, as for example \lstinline!enumTo zero! and \lstinline!sum nil!.

In general, a good black list contains only the shortest most general patterns that rule out superfluous programs. It is a question of interest how to generate such a black list automatically. We believe that good results could be achieved by exploring patterns with two or more holes and setting other functions (not only the identity) as a synthesis goal. For example, projection functions like \lstinline!proj $x_1$ $x_2$ $\ldots$ $x_n$ = $x_i$! where the types of the arguments have to be instantiated with concrete types during search could be a good start. However, since black list pruning is expensive and the black list should be short, it might be convenient to concentrate on concrete instantiations of the projection function, as we did with the identity function.


\subsection{Templates}
Another interesting question that our thesis does not answer is whether fixing the higher-order components first in form of templates helps to guide and speed up synthesis. As discussed in Section~\ref{Eval. Templates}, the successor rules currently used in our prototype implementation generate a lot of undesirable templates such as:
\begin{lstlisting}[style=plain]
?x (foldr [?X] [?Y])
?x (map [?$X_1$] [?$Y_1$]) (foldr [?$X_2$] [?$Y_2$])
\end{lstlisting}
Rewriting the successor rules or pruning templates according to some heuristic could shed light on the practical impact of this approach. In particular, we believe that limiting the size of the programs being synthesised instead of the depth of the first-order search could be a first step towards a more efficient implementation. The reason for that is that undesirable templates tend to have very few successors in the first-order search. As a result, partial programs being explored are typically quickly growing applications of holes.

\subsection{Harder benchmarks}

Experimental work is very important to understand the search space and raise new questions. We evaluated our synthesiser on simple benchmarks mostly taken from functional programming assignments, where \lstinline!enumFromTo! was the most challenging synthesis goal. However, it would be interesting to see whether our results also generalise to harder problems. We therefore encourage experiments with harder programs over trees or compound data structures.

For example, we believe that the \lstinline!waterflow! problem could pose a challenge to our synthesiser. The synthesised program should, given a list of ``wall'' heights, return the volume of the ``puddles'' that form when it rains. That is, it should satisfy the specification reported below. An expected Haskell solution is provided for reference.
\begin{lstlisting}[mathescape=false]
waterflow :: List Int -> Int
waterflow [1,2,3] == 0
waterflow [5,2,5] == 3
waterflow [2,3,1,6,1] == 2
waterflow h = sum $ 
      zipWith (-) 
        (zipWith min (scanl1 max h) (scanr1 max h))
        h
\end{lstlisting}
As you can see, the reference solution is quite long and uses many higher-order components. One of them, \lstinline!zipWith!, is even used twice. This suggests that some of the heuristics that perform well for basic benchmarks could not generalise well to harder problems.







%\subsection{Augmented specification}
%
%
%In the previous section we saw three ways the user can help the synthesiser. Another clue the user could provide, along with the input-output examples, is some intermediate value that can be produced from the given input and is used in the computation of the output.
%For example, consider we want to synthesise \lstinline!enumFromTo m n!. The list of consecutive integers from $m$ to $n$ can be computed from the list of consecutive integers from $1$ to $n-m+1$ by adding $m-1$ to each element. That is, the user could specify the synthesis task providing the following \emph{augmented examples}, the rightmost list being the expected output:
%\begin{lstlisting}[style=plain]
%enumFromTo 1 2 $\rightsquigarrow$ [1,2] $\rightsquigarrow$ [1,2]
%enumFromTo 3 4 $\rightsquigarrow$ [1,2] $\rightsquigarrow$ [3,4]
%enumFromTo 2 5 $\rightsquigarrow$ [1,2,3] $\rightsquigarrow$ [2,4,5]
%\end{lstlisting}
%The synthesiser would come up with the solution (where we substitute fully applied \lstinline!add! and \lstinline!sub! with the corresponding infix operators and \lstinline!succ zero! with $1$):
%\begin{lstlisting}[style=plain]
%enumFromTo m n = map [Int] [Int] (add (m-1)) (enumTo (n-m+1))
%\end{lstlisting}
%The open question is how to use the augmented examples to restrict the search space and suggest the relevant library components to the synthesiser. 
%Moreover, the user-synthesiser interaction can be brought to a new level by permitting the synthesiser to explicitly ask the user for help. For example, when coming up with intermediate values, the synthesiser could ask whether they are relevant to the current synthesis task.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
